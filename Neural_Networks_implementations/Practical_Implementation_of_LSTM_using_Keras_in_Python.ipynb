{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical Implementation of LSTM using Keras in Python.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "duOfex0RYD7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWa5Pr6oYL_a",
        "colab_type": "text"
      },
      "source": [
        "# Practical Implementation of LSTM using Keras in Python\n",
        "\n",
        " ## Contents to be covered in this notebook:\n",
        "\n",
        " - LSTM Implementation\n",
        " - Visualize the results and convergence\n",
        "\n",
        " In this notebook we will predict the next number of series.\n",
        "\n",
        " For example:\n",
        "#### Training Data\n",
        "       X                Y\n",
        " ---------------     -------\n",
        "- 1, 2, 3, 4, 5 =>>>>>>> 6\n",
        "- 2, 3, 4, 5, 6 =>>>>>>> 7\n",
        "- 3, 4, 5, 6, 7 =>>>>>>> 8\n",
        "- 4, 5, 6, 7, 8 =>>>>>>> 9\n",
        "----------------------------\n",
        "#### Test Data\n",
        " X ............................................. Y\n",
        " ---------------------     -------\n",
        " - 10, 11, 12, 13, 14 =>>>>  ???\n",
        " - 11, 12, 13, 14, 15 =>>>>  ???\n",
        " - 12, 13, 14, 15, 16 =>>>>  ???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOrz-4IfbPAV",
        "colab_type": "text"
      },
      "source": [
        "#### Import Important Libraries first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzUSIy-cbM4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0erJQiIckNS",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation as discussed above in detail"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE_HPmzvcpRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code will generate the 100 vectors of 5 consecutive digits into variable name data\n",
        "Data = [[[(i+j)/100] for i in range(5)] for j in range(100)] \n",
        "target = [(i+5)/100 for i in range(100)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjopab7Nc8Q_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07af5676-5597-4014-9d31-5629cdcb3832"
      },
      "source": [
        "Data"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[0.0], [0.01], [0.02], [0.03], [0.04]],\n",
              " [[0.01], [0.02], [0.03], [0.04], [0.05]],\n",
              " [[0.02], [0.03], [0.04], [0.05], [0.06]],\n",
              " [[0.03], [0.04], [0.05], [0.06], [0.07]],\n",
              " [[0.04], [0.05], [0.06], [0.07], [0.08]],\n",
              " [[0.05], [0.06], [0.07], [0.08], [0.09]],\n",
              " [[0.06], [0.07], [0.08], [0.09], [0.1]],\n",
              " [[0.07], [0.08], [0.09], [0.1], [0.11]],\n",
              " [[0.08], [0.09], [0.1], [0.11], [0.12]],\n",
              " [[0.09], [0.1], [0.11], [0.12], [0.13]],\n",
              " [[0.1], [0.11], [0.12], [0.13], [0.14]],\n",
              " [[0.11], [0.12], [0.13], [0.14], [0.15]],\n",
              " [[0.12], [0.13], [0.14], [0.15], [0.16]],\n",
              " [[0.13], [0.14], [0.15], [0.16], [0.17]],\n",
              " [[0.14], [0.15], [0.16], [0.17], [0.18]],\n",
              " [[0.15], [0.16], [0.17], [0.18], [0.19]],\n",
              " [[0.16], [0.17], [0.18], [0.19], [0.2]],\n",
              " [[0.17], [0.18], [0.19], [0.2], [0.21]],\n",
              " [[0.18], [0.19], [0.2], [0.21], [0.22]],\n",
              " [[0.19], [0.2], [0.21], [0.22], [0.23]],\n",
              " [[0.2], [0.21], [0.22], [0.23], [0.24]],\n",
              " [[0.21], [0.22], [0.23], [0.24], [0.25]],\n",
              " [[0.22], [0.23], [0.24], [0.25], [0.26]],\n",
              " [[0.23], [0.24], [0.25], [0.26], [0.27]],\n",
              " [[0.24], [0.25], [0.26], [0.27], [0.28]],\n",
              " [[0.25], [0.26], [0.27], [0.28], [0.29]],\n",
              " [[0.26], [0.27], [0.28], [0.29], [0.3]],\n",
              " [[0.27], [0.28], [0.29], [0.3], [0.31]],\n",
              " [[0.28], [0.29], [0.3], [0.31], [0.32]],\n",
              " [[0.29], [0.3], [0.31], [0.32], [0.33]],\n",
              " [[0.3], [0.31], [0.32], [0.33], [0.34]],\n",
              " [[0.31], [0.32], [0.33], [0.34], [0.35]],\n",
              " [[0.32], [0.33], [0.34], [0.35], [0.36]],\n",
              " [[0.33], [0.34], [0.35], [0.36], [0.37]],\n",
              " [[0.34], [0.35], [0.36], [0.37], [0.38]],\n",
              " [[0.35], [0.36], [0.37], [0.38], [0.39]],\n",
              " [[0.36], [0.37], [0.38], [0.39], [0.4]],\n",
              " [[0.37], [0.38], [0.39], [0.4], [0.41]],\n",
              " [[0.38], [0.39], [0.4], [0.41], [0.42]],\n",
              " [[0.39], [0.4], [0.41], [0.42], [0.43]],\n",
              " [[0.4], [0.41], [0.42], [0.43], [0.44]],\n",
              " [[0.41], [0.42], [0.43], [0.44], [0.45]],\n",
              " [[0.42], [0.43], [0.44], [0.45], [0.46]],\n",
              " [[0.43], [0.44], [0.45], [0.46], [0.47]],\n",
              " [[0.44], [0.45], [0.46], [0.47], [0.48]],\n",
              " [[0.45], [0.46], [0.47], [0.48], [0.49]],\n",
              " [[0.46], [0.47], [0.48], [0.49], [0.5]],\n",
              " [[0.47], [0.48], [0.49], [0.5], [0.51]],\n",
              " [[0.48], [0.49], [0.5], [0.51], [0.52]],\n",
              " [[0.49], [0.5], [0.51], [0.52], [0.53]],\n",
              " [[0.5], [0.51], [0.52], [0.53], [0.54]],\n",
              " [[0.51], [0.52], [0.53], [0.54], [0.55]],\n",
              " [[0.52], [0.53], [0.54], [0.55], [0.56]],\n",
              " [[0.53], [0.54], [0.55], [0.56], [0.57]],\n",
              " [[0.54], [0.55], [0.56], [0.57], [0.58]],\n",
              " [[0.55], [0.56], [0.57], [0.58], [0.59]],\n",
              " [[0.56], [0.57], [0.58], [0.59], [0.6]],\n",
              " [[0.57], [0.58], [0.59], [0.6], [0.61]],\n",
              " [[0.58], [0.59], [0.6], [0.61], [0.62]],\n",
              " [[0.59], [0.6], [0.61], [0.62], [0.63]],\n",
              " [[0.6], [0.61], [0.62], [0.63], [0.64]],\n",
              " [[0.61], [0.62], [0.63], [0.64], [0.65]],\n",
              " [[0.62], [0.63], [0.64], [0.65], [0.66]],\n",
              " [[0.63], [0.64], [0.65], [0.66], [0.67]],\n",
              " [[0.64], [0.65], [0.66], [0.67], [0.68]],\n",
              " [[0.65], [0.66], [0.67], [0.68], [0.69]],\n",
              " [[0.66], [0.67], [0.68], [0.69], [0.7]],\n",
              " [[0.67], [0.68], [0.69], [0.7], [0.71]],\n",
              " [[0.68], [0.69], [0.7], [0.71], [0.72]],\n",
              " [[0.69], [0.7], [0.71], [0.72], [0.73]],\n",
              " [[0.7], [0.71], [0.72], [0.73], [0.74]],\n",
              " [[0.71], [0.72], [0.73], [0.74], [0.75]],\n",
              " [[0.72], [0.73], [0.74], [0.75], [0.76]],\n",
              " [[0.73], [0.74], [0.75], [0.76], [0.77]],\n",
              " [[0.74], [0.75], [0.76], [0.77], [0.78]],\n",
              " [[0.75], [0.76], [0.77], [0.78], [0.79]],\n",
              " [[0.76], [0.77], [0.78], [0.79], [0.8]],\n",
              " [[0.77], [0.78], [0.79], [0.8], [0.81]],\n",
              " [[0.78], [0.79], [0.8], [0.81], [0.82]],\n",
              " [[0.79], [0.8], [0.81], [0.82], [0.83]],\n",
              " [[0.8], [0.81], [0.82], [0.83], [0.84]],\n",
              " [[0.81], [0.82], [0.83], [0.84], [0.85]],\n",
              " [[0.82], [0.83], [0.84], [0.85], [0.86]],\n",
              " [[0.83], [0.84], [0.85], [0.86], [0.87]],\n",
              " [[0.84], [0.85], [0.86], [0.87], [0.88]],\n",
              " [[0.85], [0.86], [0.87], [0.88], [0.89]],\n",
              " [[0.86], [0.87], [0.88], [0.89], [0.9]],\n",
              " [[0.87], [0.88], [0.89], [0.9], [0.91]],\n",
              " [[0.88], [0.89], [0.9], [0.91], [0.92]],\n",
              " [[0.89], [0.9], [0.91], [0.92], [0.93]],\n",
              " [[0.9], [0.91], [0.92], [0.93], [0.94]],\n",
              " [[0.91], [0.92], [0.93], [0.94], [0.95]],\n",
              " [[0.92], [0.93], [0.94], [0.95], [0.96]],\n",
              " [[0.93], [0.94], [0.95], [0.96], [0.97]],\n",
              " [[0.94], [0.95], [0.96], [0.97], [0.98]],\n",
              " [[0.95], [0.96], [0.97], [0.98], [0.99]],\n",
              " [[0.96], [0.97], [0.98], [0.99], [1.0]],\n",
              " [[0.97], [0.98], [0.99], [1.0], [1.01]],\n",
              " [[0.98], [0.99], [1.0], [1.01], [1.02]],\n",
              " [[0.99], [1.0], [1.01], [1.02], [1.03]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS214-EQdjBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c5b4bfa-6d18-4a75-cd06-5a870cc96930"
      },
      "source": [
        "target"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05,\n",
              " 0.06,\n",
              " 0.07,\n",
              " 0.08,\n",
              " 0.09,\n",
              " 0.1,\n",
              " 0.11,\n",
              " 0.12,\n",
              " 0.13,\n",
              " 0.14,\n",
              " 0.15,\n",
              " 0.16,\n",
              " 0.17,\n",
              " 0.18,\n",
              " 0.19,\n",
              " 0.2,\n",
              " 0.21,\n",
              " 0.22,\n",
              " 0.23,\n",
              " 0.24,\n",
              " 0.25,\n",
              " 0.26,\n",
              " 0.27,\n",
              " 0.28,\n",
              " 0.29,\n",
              " 0.3,\n",
              " 0.31,\n",
              " 0.32,\n",
              " 0.33,\n",
              " 0.34,\n",
              " 0.35,\n",
              " 0.36,\n",
              " 0.37,\n",
              " 0.38,\n",
              " 0.39,\n",
              " 0.4,\n",
              " 0.41,\n",
              " 0.42,\n",
              " 0.43,\n",
              " 0.44,\n",
              " 0.45,\n",
              " 0.46,\n",
              " 0.47,\n",
              " 0.48,\n",
              " 0.49,\n",
              " 0.5,\n",
              " 0.51,\n",
              " 0.52,\n",
              " 0.53,\n",
              " 0.54,\n",
              " 0.55,\n",
              " 0.56,\n",
              " 0.57,\n",
              " 0.58,\n",
              " 0.59,\n",
              " 0.6,\n",
              " 0.61,\n",
              " 0.62,\n",
              " 0.63,\n",
              " 0.64,\n",
              " 0.65,\n",
              " 0.66,\n",
              " 0.67,\n",
              " 0.68,\n",
              " 0.69,\n",
              " 0.7,\n",
              " 0.71,\n",
              " 0.72,\n",
              " 0.73,\n",
              " 0.74,\n",
              " 0.75,\n",
              " 0.76,\n",
              " 0.77,\n",
              " 0.78,\n",
              " 0.79,\n",
              " 0.8,\n",
              " 0.81,\n",
              " 0.82,\n",
              " 0.83,\n",
              " 0.84,\n",
              " 0.85,\n",
              " 0.86,\n",
              " 0.87,\n",
              " 0.88,\n",
              " 0.89,\n",
              " 0.9,\n",
              " 0.91,\n",
              " 0.92,\n",
              " 0.93,\n",
              " 0.94,\n",
              " 0.95,\n",
              " 0.96,\n",
              " 0.97,\n",
              " 0.98,\n",
              " 0.99,\n",
              " 1.0,\n",
              " 1.01,\n",
              " 1.02,\n",
              " 1.03,\n",
              " 1.04]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKAUW-RRduX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now convert both arrays into Numpy arrays\n",
        "data = np.array(Data, dtype=float)\n",
        "target = np.array(target, dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh3rkEfMeuKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03dda55d-3b03-4c7c-8dbc-6216c529ba0b"
      },
      "source": [
        "data"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.  ],\n",
              "        [0.01],\n",
              "        [0.02],\n",
              "        [0.03],\n",
              "        [0.04]],\n",
              "\n",
              "       [[0.01],\n",
              "        [0.02],\n",
              "        [0.03],\n",
              "        [0.04],\n",
              "        [0.05]],\n",
              "\n",
              "       [[0.02],\n",
              "        [0.03],\n",
              "        [0.04],\n",
              "        [0.05],\n",
              "        [0.06]],\n",
              "\n",
              "       [[0.03],\n",
              "        [0.04],\n",
              "        [0.05],\n",
              "        [0.06],\n",
              "        [0.07]],\n",
              "\n",
              "       [[0.04],\n",
              "        [0.05],\n",
              "        [0.06],\n",
              "        [0.07],\n",
              "        [0.08]],\n",
              "\n",
              "       [[0.05],\n",
              "        [0.06],\n",
              "        [0.07],\n",
              "        [0.08],\n",
              "        [0.09]],\n",
              "\n",
              "       [[0.06],\n",
              "        [0.07],\n",
              "        [0.08],\n",
              "        [0.09],\n",
              "        [0.1 ]],\n",
              "\n",
              "       [[0.07],\n",
              "        [0.08],\n",
              "        [0.09],\n",
              "        [0.1 ],\n",
              "        [0.11]],\n",
              "\n",
              "       [[0.08],\n",
              "        [0.09],\n",
              "        [0.1 ],\n",
              "        [0.11],\n",
              "        [0.12]],\n",
              "\n",
              "       [[0.09],\n",
              "        [0.1 ],\n",
              "        [0.11],\n",
              "        [0.12],\n",
              "        [0.13]],\n",
              "\n",
              "       [[0.1 ],\n",
              "        [0.11],\n",
              "        [0.12],\n",
              "        [0.13],\n",
              "        [0.14]],\n",
              "\n",
              "       [[0.11],\n",
              "        [0.12],\n",
              "        [0.13],\n",
              "        [0.14],\n",
              "        [0.15]],\n",
              "\n",
              "       [[0.12],\n",
              "        [0.13],\n",
              "        [0.14],\n",
              "        [0.15],\n",
              "        [0.16]],\n",
              "\n",
              "       [[0.13],\n",
              "        [0.14],\n",
              "        [0.15],\n",
              "        [0.16],\n",
              "        [0.17]],\n",
              "\n",
              "       [[0.14],\n",
              "        [0.15],\n",
              "        [0.16],\n",
              "        [0.17],\n",
              "        [0.18]],\n",
              "\n",
              "       [[0.15],\n",
              "        [0.16],\n",
              "        [0.17],\n",
              "        [0.18],\n",
              "        [0.19]],\n",
              "\n",
              "       [[0.16],\n",
              "        [0.17],\n",
              "        [0.18],\n",
              "        [0.19],\n",
              "        [0.2 ]],\n",
              "\n",
              "       [[0.17],\n",
              "        [0.18],\n",
              "        [0.19],\n",
              "        [0.2 ],\n",
              "        [0.21]],\n",
              "\n",
              "       [[0.18],\n",
              "        [0.19],\n",
              "        [0.2 ],\n",
              "        [0.21],\n",
              "        [0.22]],\n",
              "\n",
              "       [[0.19],\n",
              "        [0.2 ],\n",
              "        [0.21],\n",
              "        [0.22],\n",
              "        [0.23]],\n",
              "\n",
              "       [[0.2 ],\n",
              "        [0.21],\n",
              "        [0.22],\n",
              "        [0.23],\n",
              "        [0.24]],\n",
              "\n",
              "       [[0.21],\n",
              "        [0.22],\n",
              "        [0.23],\n",
              "        [0.24],\n",
              "        [0.25]],\n",
              "\n",
              "       [[0.22],\n",
              "        [0.23],\n",
              "        [0.24],\n",
              "        [0.25],\n",
              "        [0.26]],\n",
              "\n",
              "       [[0.23],\n",
              "        [0.24],\n",
              "        [0.25],\n",
              "        [0.26],\n",
              "        [0.27]],\n",
              "\n",
              "       [[0.24],\n",
              "        [0.25],\n",
              "        [0.26],\n",
              "        [0.27],\n",
              "        [0.28]],\n",
              "\n",
              "       [[0.25],\n",
              "        [0.26],\n",
              "        [0.27],\n",
              "        [0.28],\n",
              "        [0.29]],\n",
              "\n",
              "       [[0.26],\n",
              "        [0.27],\n",
              "        [0.28],\n",
              "        [0.29],\n",
              "        [0.3 ]],\n",
              "\n",
              "       [[0.27],\n",
              "        [0.28],\n",
              "        [0.29],\n",
              "        [0.3 ],\n",
              "        [0.31]],\n",
              "\n",
              "       [[0.28],\n",
              "        [0.29],\n",
              "        [0.3 ],\n",
              "        [0.31],\n",
              "        [0.32]],\n",
              "\n",
              "       [[0.29],\n",
              "        [0.3 ],\n",
              "        [0.31],\n",
              "        [0.32],\n",
              "        [0.33]],\n",
              "\n",
              "       [[0.3 ],\n",
              "        [0.31],\n",
              "        [0.32],\n",
              "        [0.33],\n",
              "        [0.34]],\n",
              "\n",
              "       [[0.31],\n",
              "        [0.32],\n",
              "        [0.33],\n",
              "        [0.34],\n",
              "        [0.35]],\n",
              "\n",
              "       [[0.32],\n",
              "        [0.33],\n",
              "        [0.34],\n",
              "        [0.35],\n",
              "        [0.36]],\n",
              "\n",
              "       [[0.33],\n",
              "        [0.34],\n",
              "        [0.35],\n",
              "        [0.36],\n",
              "        [0.37]],\n",
              "\n",
              "       [[0.34],\n",
              "        [0.35],\n",
              "        [0.36],\n",
              "        [0.37],\n",
              "        [0.38]],\n",
              "\n",
              "       [[0.35],\n",
              "        [0.36],\n",
              "        [0.37],\n",
              "        [0.38],\n",
              "        [0.39]],\n",
              "\n",
              "       [[0.36],\n",
              "        [0.37],\n",
              "        [0.38],\n",
              "        [0.39],\n",
              "        [0.4 ]],\n",
              "\n",
              "       [[0.37],\n",
              "        [0.38],\n",
              "        [0.39],\n",
              "        [0.4 ],\n",
              "        [0.41]],\n",
              "\n",
              "       [[0.38],\n",
              "        [0.39],\n",
              "        [0.4 ],\n",
              "        [0.41],\n",
              "        [0.42]],\n",
              "\n",
              "       [[0.39],\n",
              "        [0.4 ],\n",
              "        [0.41],\n",
              "        [0.42],\n",
              "        [0.43]],\n",
              "\n",
              "       [[0.4 ],\n",
              "        [0.41],\n",
              "        [0.42],\n",
              "        [0.43],\n",
              "        [0.44]],\n",
              "\n",
              "       [[0.41],\n",
              "        [0.42],\n",
              "        [0.43],\n",
              "        [0.44],\n",
              "        [0.45]],\n",
              "\n",
              "       [[0.42],\n",
              "        [0.43],\n",
              "        [0.44],\n",
              "        [0.45],\n",
              "        [0.46]],\n",
              "\n",
              "       [[0.43],\n",
              "        [0.44],\n",
              "        [0.45],\n",
              "        [0.46],\n",
              "        [0.47]],\n",
              "\n",
              "       [[0.44],\n",
              "        [0.45],\n",
              "        [0.46],\n",
              "        [0.47],\n",
              "        [0.48]],\n",
              "\n",
              "       [[0.45],\n",
              "        [0.46],\n",
              "        [0.47],\n",
              "        [0.48],\n",
              "        [0.49]],\n",
              "\n",
              "       [[0.46],\n",
              "        [0.47],\n",
              "        [0.48],\n",
              "        [0.49],\n",
              "        [0.5 ]],\n",
              "\n",
              "       [[0.47],\n",
              "        [0.48],\n",
              "        [0.49],\n",
              "        [0.5 ],\n",
              "        [0.51]],\n",
              "\n",
              "       [[0.48],\n",
              "        [0.49],\n",
              "        [0.5 ],\n",
              "        [0.51],\n",
              "        [0.52]],\n",
              "\n",
              "       [[0.49],\n",
              "        [0.5 ],\n",
              "        [0.51],\n",
              "        [0.52],\n",
              "        [0.53]],\n",
              "\n",
              "       [[0.5 ],\n",
              "        [0.51],\n",
              "        [0.52],\n",
              "        [0.53],\n",
              "        [0.54]],\n",
              "\n",
              "       [[0.51],\n",
              "        [0.52],\n",
              "        [0.53],\n",
              "        [0.54],\n",
              "        [0.55]],\n",
              "\n",
              "       [[0.52],\n",
              "        [0.53],\n",
              "        [0.54],\n",
              "        [0.55],\n",
              "        [0.56]],\n",
              "\n",
              "       [[0.53],\n",
              "        [0.54],\n",
              "        [0.55],\n",
              "        [0.56],\n",
              "        [0.57]],\n",
              "\n",
              "       [[0.54],\n",
              "        [0.55],\n",
              "        [0.56],\n",
              "        [0.57],\n",
              "        [0.58]],\n",
              "\n",
              "       [[0.55],\n",
              "        [0.56],\n",
              "        [0.57],\n",
              "        [0.58],\n",
              "        [0.59]],\n",
              "\n",
              "       [[0.56],\n",
              "        [0.57],\n",
              "        [0.58],\n",
              "        [0.59],\n",
              "        [0.6 ]],\n",
              "\n",
              "       [[0.57],\n",
              "        [0.58],\n",
              "        [0.59],\n",
              "        [0.6 ],\n",
              "        [0.61]],\n",
              "\n",
              "       [[0.58],\n",
              "        [0.59],\n",
              "        [0.6 ],\n",
              "        [0.61],\n",
              "        [0.62]],\n",
              "\n",
              "       [[0.59],\n",
              "        [0.6 ],\n",
              "        [0.61],\n",
              "        [0.62],\n",
              "        [0.63]],\n",
              "\n",
              "       [[0.6 ],\n",
              "        [0.61],\n",
              "        [0.62],\n",
              "        [0.63],\n",
              "        [0.64]],\n",
              "\n",
              "       [[0.61],\n",
              "        [0.62],\n",
              "        [0.63],\n",
              "        [0.64],\n",
              "        [0.65]],\n",
              "\n",
              "       [[0.62],\n",
              "        [0.63],\n",
              "        [0.64],\n",
              "        [0.65],\n",
              "        [0.66]],\n",
              "\n",
              "       [[0.63],\n",
              "        [0.64],\n",
              "        [0.65],\n",
              "        [0.66],\n",
              "        [0.67]],\n",
              "\n",
              "       [[0.64],\n",
              "        [0.65],\n",
              "        [0.66],\n",
              "        [0.67],\n",
              "        [0.68]],\n",
              "\n",
              "       [[0.65],\n",
              "        [0.66],\n",
              "        [0.67],\n",
              "        [0.68],\n",
              "        [0.69]],\n",
              "\n",
              "       [[0.66],\n",
              "        [0.67],\n",
              "        [0.68],\n",
              "        [0.69],\n",
              "        [0.7 ]],\n",
              "\n",
              "       [[0.67],\n",
              "        [0.68],\n",
              "        [0.69],\n",
              "        [0.7 ],\n",
              "        [0.71]],\n",
              "\n",
              "       [[0.68],\n",
              "        [0.69],\n",
              "        [0.7 ],\n",
              "        [0.71],\n",
              "        [0.72]],\n",
              "\n",
              "       [[0.69],\n",
              "        [0.7 ],\n",
              "        [0.71],\n",
              "        [0.72],\n",
              "        [0.73]],\n",
              "\n",
              "       [[0.7 ],\n",
              "        [0.71],\n",
              "        [0.72],\n",
              "        [0.73],\n",
              "        [0.74]],\n",
              "\n",
              "       [[0.71],\n",
              "        [0.72],\n",
              "        [0.73],\n",
              "        [0.74],\n",
              "        [0.75]],\n",
              "\n",
              "       [[0.72],\n",
              "        [0.73],\n",
              "        [0.74],\n",
              "        [0.75],\n",
              "        [0.76]],\n",
              "\n",
              "       [[0.73],\n",
              "        [0.74],\n",
              "        [0.75],\n",
              "        [0.76],\n",
              "        [0.77]],\n",
              "\n",
              "       [[0.74],\n",
              "        [0.75],\n",
              "        [0.76],\n",
              "        [0.77],\n",
              "        [0.78]],\n",
              "\n",
              "       [[0.75],\n",
              "        [0.76],\n",
              "        [0.77],\n",
              "        [0.78],\n",
              "        [0.79]],\n",
              "\n",
              "       [[0.76],\n",
              "        [0.77],\n",
              "        [0.78],\n",
              "        [0.79],\n",
              "        [0.8 ]],\n",
              "\n",
              "       [[0.77],\n",
              "        [0.78],\n",
              "        [0.79],\n",
              "        [0.8 ],\n",
              "        [0.81]],\n",
              "\n",
              "       [[0.78],\n",
              "        [0.79],\n",
              "        [0.8 ],\n",
              "        [0.81],\n",
              "        [0.82]],\n",
              "\n",
              "       [[0.79],\n",
              "        [0.8 ],\n",
              "        [0.81],\n",
              "        [0.82],\n",
              "        [0.83]],\n",
              "\n",
              "       [[0.8 ],\n",
              "        [0.81],\n",
              "        [0.82],\n",
              "        [0.83],\n",
              "        [0.84]],\n",
              "\n",
              "       [[0.81],\n",
              "        [0.82],\n",
              "        [0.83],\n",
              "        [0.84],\n",
              "        [0.85]],\n",
              "\n",
              "       [[0.82],\n",
              "        [0.83],\n",
              "        [0.84],\n",
              "        [0.85],\n",
              "        [0.86]],\n",
              "\n",
              "       [[0.83],\n",
              "        [0.84],\n",
              "        [0.85],\n",
              "        [0.86],\n",
              "        [0.87]],\n",
              "\n",
              "       [[0.84],\n",
              "        [0.85],\n",
              "        [0.86],\n",
              "        [0.87],\n",
              "        [0.88]],\n",
              "\n",
              "       [[0.85],\n",
              "        [0.86],\n",
              "        [0.87],\n",
              "        [0.88],\n",
              "        [0.89]],\n",
              "\n",
              "       [[0.86],\n",
              "        [0.87],\n",
              "        [0.88],\n",
              "        [0.89],\n",
              "        [0.9 ]],\n",
              "\n",
              "       [[0.87],\n",
              "        [0.88],\n",
              "        [0.89],\n",
              "        [0.9 ],\n",
              "        [0.91]],\n",
              "\n",
              "       [[0.88],\n",
              "        [0.89],\n",
              "        [0.9 ],\n",
              "        [0.91],\n",
              "        [0.92]],\n",
              "\n",
              "       [[0.89],\n",
              "        [0.9 ],\n",
              "        [0.91],\n",
              "        [0.92],\n",
              "        [0.93]],\n",
              "\n",
              "       [[0.9 ],\n",
              "        [0.91],\n",
              "        [0.92],\n",
              "        [0.93],\n",
              "        [0.94]],\n",
              "\n",
              "       [[0.91],\n",
              "        [0.92],\n",
              "        [0.93],\n",
              "        [0.94],\n",
              "        [0.95]],\n",
              "\n",
              "       [[0.92],\n",
              "        [0.93],\n",
              "        [0.94],\n",
              "        [0.95],\n",
              "        [0.96]],\n",
              "\n",
              "       [[0.93],\n",
              "        [0.94],\n",
              "        [0.95],\n",
              "        [0.96],\n",
              "        [0.97]],\n",
              "\n",
              "       [[0.94],\n",
              "        [0.95],\n",
              "        [0.96],\n",
              "        [0.97],\n",
              "        [0.98]],\n",
              "\n",
              "       [[0.95],\n",
              "        [0.96],\n",
              "        [0.97],\n",
              "        [0.98],\n",
              "        [0.99]],\n",
              "\n",
              "       [[0.96],\n",
              "        [0.97],\n",
              "        [0.98],\n",
              "        [0.99],\n",
              "        [1.  ]],\n",
              "\n",
              "       [[0.97],\n",
              "        [0.98],\n",
              "        [0.99],\n",
              "        [1.  ],\n",
              "        [1.01]],\n",
              "\n",
              "       [[0.98],\n",
              "        [0.99],\n",
              "        [1.  ],\n",
              "        [1.01],\n",
              "        [1.02]],\n",
              "\n",
              "       [[0.99],\n",
              "        [1.  ],\n",
              "        [1.01],\n",
              "        [1.02],\n",
              "        [1.03]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDCcU9UheviK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0aec5bee-7ec4-4dc4-8e1f-6886c6bad4c8"
      },
      "source": [
        "target"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11, 0.12, 0.13, 0.14, 0.15,\n",
              "       0.16, 0.17, 0.18, 0.19, 0.2 , 0.21, 0.22, 0.23, 0.24, 0.25, 0.26,\n",
              "       0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37,\n",
              "       0.38, 0.39, 0.4 , 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48,\n",
              "       0.49, 0.5 , 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59,\n",
              "       0.6 , 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7 ,\n",
              "       0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8 , 0.81,\n",
              "       0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9 , 0.91, 0.92,\n",
              "       0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.  , 1.01, 1.02, 1.03,\n",
              "       1.04])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYh7weEKexdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now split the data into train_test for training and testing purpose\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwKl6vCNffSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now configure LSTM model\n",
        "model=Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf2VVmsFfxbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(LSTM((1), batch_input_shape=(None, 5, 1), return_sequences = False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_3H-_Wygapp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtRKYbrKigpr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e4e6ef7c-7f57-43c8-900c-ca9586f8bc7b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_17 (LSTM)               (None, 1)                 12        \n",
            "=================================================================\n",
            "Total params: 12\n",
            "Trainable params: 12\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2FEuVoOimwz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "364429db-2761-43ec-85ff-c0a2bdb3279d"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=600, validation_data=(x_test, y_test))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80 samples, validate on 20 samples\n",
            "Epoch 1/600\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0297 - accuracy: 0.0000e+00 - val_loss: 0.0288 - val_accuracy: 0.0500\n",
            "Epoch 2/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0296 - accuracy: 0.0000e+00 - val_loss: 0.0288 - val_accuracy: 0.0500\n",
            "Epoch 3/600\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0296 - accuracy: 0.0000e+00 - val_loss: 0.0289 - val_accuracy: 0.0500\n",
            "Epoch 4/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0295 - accuracy: 0.0000e+00 - val_loss: 0.0289 - val_accuracy: 0.0500\n",
            "Epoch 5/600\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0295 - accuracy: 0.0000e+00 - val_loss: 0.0289 - val_accuracy: 0.0500\n",
            "Epoch 6/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0295 - accuracy: 0.0000e+00 - val_loss: 0.0291 - val_accuracy: 0.0500\n",
            "Epoch 7/600\n",
            "80/80 [==============================] - 0s 179us/step - loss: 0.0295 - accuracy: 0.0000e+00 - val_loss: 0.0292 - val_accuracy: 0.0500\n",
            "Epoch 8/600\n",
            "80/80 [==============================] - 0s 165us/step - loss: 0.0294 - accuracy: 0.0000e+00 - val_loss: 0.0291 - val_accuracy: 0.0500\n",
            "Epoch 9/600\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0294 - accuracy: 0.0000e+00 - val_loss: 0.0290 - val_accuracy: 0.0500\n",
            "Epoch 10/600\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0294 - accuracy: 0.0000e+00 - val_loss: 0.0288 - val_accuracy: 0.0500\n",
            "Epoch 11/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0293 - accuracy: 0.0000e+00 - val_loss: 0.0288 - val_accuracy: 0.0500\n",
            "Epoch 12/600\n",
            "80/80 [==============================] - 0s 148us/step - loss: 0.0293 - accuracy: 0.0000e+00 - val_loss: 0.0288 - val_accuracy: 0.0500\n",
            "Epoch 13/600\n",
            "80/80 [==============================] - 0s 260us/step - loss: 0.0293 - accuracy: 0.0000e+00 - val_loss: 0.0287 - val_accuracy: 0.0500\n",
            "Epoch 14/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0292 - accuracy: 0.0000e+00 - val_loss: 0.0288 - val_accuracy: 0.0500\n",
            "Epoch 15/600\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0292 - accuracy: 0.0000e+00 - val_loss: 0.0289 - val_accuracy: 0.0500\n",
            "Epoch 16/600\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0292 - accuracy: 0.0000e+00 - val_loss: 0.0290 - val_accuracy: 0.0500\n",
            "Epoch 17/600\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0292 - accuracy: 0.0000e+00 - val_loss: 0.0289 - val_accuracy: 0.0500\n",
            "Epoch 18/600\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0291 - accuracy: 0.0000e+00 - val_loss: 0.0289 - val_accuracy: 0.0500\n",
            "Epoch 19/600\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0291 - accuracy: 0.0000e+00 - val_loss: 0.0288 - val_accuracy: 0.0500\n",
            "Epoch 20/600\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0290 - accuracy: 0.0000e+00 - val_loss: 0.0286 - val_accuracy: 0.0500\n",
            "Epoch 21/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0290 - accuracy: 0.0000e+00 - val_loss: 0.0285 - val_accuracy: 0.0500\n",
            "Epoch 22/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0290 - accuracy: 0.0000e+00 - val_loss: 0.0281 - val_accuracy: 0.0500\n",
            "Epoch 23/600\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0290 - accuracy: 0.0000e+00 - val_loss: 0.0282 - val_accuracy: 0.0500\n",
            "Epoch 24/600\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0290 - accuracy: 0.0000e+00 - val_loss: 0.0283 - val_accuracy: 0.0500\n",
            "Epoch 25/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0289 - accuracy: 0.0000e+00 - val_loss: 0.0282 - val_accuracy: 0.0500\n",
            "Epoch 26/600\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0289 - accuracy: 0.0000e+00 - val_loss: 0.0283 - val_accuracy: 0.0500\n",
            "Epoch 27/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0288 - accuracy: 0.0000e+00 - val_loss: 0.0287 - val_accuracy: 0.0500\n",
            "Epoch 28/600\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0288 - accuracy: 0.0000e+00 - val_loss: 0.0288 - val_accuracy: 0.0500\n",
            "Epoch 29/600\n",
            "80/80 [==============================] - 0s 172us/step - loss: 0.0288 - accuracy: 0.0000e+00 - val_loss: 0.0289 - val_accuracy: 0.0500\n",
            "Epoch 30/600\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0288 - accuracy: 0.0000e+00 - val_loss: 0.0287 - val_accuracy: 0.0500\n",
            "Epoch 31/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0287 - accuracy: 0.0000e+00 - val_loss: 0.0284 - val_accuracy: 0.0500\n",
            "Epoch 32/600\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0287 - accuracy: 0.0000e+00 - val_loss: 0.0283 - val_accuracy: 0.0500\n",
            "Epoch 33/600\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0286 - accuracy: 0.0000e+00 - val_loss: 0.0282 - val_accuracy: 0.0500\n",
            "Epoch 34/600\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0286 - accuracy: 0.0000e+00 - val_loss: 0.0280 - val_accuracy: 0.0500\n",
            "Epoch 35/600\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0286 - accuracy: 0.0000e+00 - val_loss: 0.0280 - val_accuracy: 0.0500\n",
            "Epoch 36/600\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0286 - accuracy: 0.0000e+00 - val_loss: 0.0280 - val_accuracy: 0.0500\n",
            "Epoch 37/600\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0285 - accuracy: 0.0000e+00 - val_loss: 0.0281 - val_accuracy: 0.0500\n",
            "Epoch 38/600\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0285 - accuracy: 0.0000e+00 - val_loss: 0.0283 - val_accuracy: 0.0500\n",
            "Epoch 39/600\n",
            "80/80 [==============================] - 0s 239us/step - loss: 0.0285 - accuracy: 0.0000e+00 - val_loss: 0.0283 - val_accuracy: 0.0500\n",
            "Epoch 40/600\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0285 - accuracy: 0.0000e+00 - val_loss: 0.0282 - val_accuracy: 0.0500\n",
            "Epoch 41/600\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0284 - accuracy: 0.0000e+00 - val_loss: 0.0282 - val_accuracy: 0.0500\n",
            "Epoch 42/600\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0284 - accuracy: 0.0000e+00 - val_loss: 0.0282 - val_accuracy: 0.0500\n",
            "Epoch 43/600\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0284 - accuracy: 0.0000e+00 - val_loss: 0.0282 - val_accuracy: 0.0500\n",
            "Epoch 44/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0283 - accuracy: 0.0000e+00 - val_loss: 0.0281 - val_accuracy: 0.0500\n",
            "Epoch 45/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0283 - accuracy: 0.0000e+00 - val_loss: 0.0279 - val_accuracy: 0.0500\n",
            "Epoch 46/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0283 - accuracy: 0.0000e+00 - val_loss: 0.0277 - val_accuracy: 0.0500\n",
            "Epoch 47/600\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0283 - accuracy: 0.0000e+00 - val_loss: 0.0276 - val_accuracy: 0.0500\n",
            "Epoch 48/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0282 - accuracy: 0.0000e+00 - val_loss: 0.0277 - val_accuracy: 0.0500\n",
            "Epoch 49/600\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0282 - accuracy: 0.0000e+00 - val_loss: 0.0278 - val_accuracy: 0.0500\n",
            "Epoch 50/600\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0282 - accuracy: 0.0000e+00 - val_loss: 0.0279 - val_accuracy: 0.0500\n",
            "Epoch 51/600\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0282 - accuracy: 0.0000e+00 - val_loss: 0.0277 - val_accuracy: 0.0500\n",
            "Epoch 52/600\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0281 - accuracy: 0.0000e+00 - val_loss: 0.0277 - val_accuracy: 0.0500\n",
            "Epoch 53/600\n",
            "80/80 [==============================] - 0s 278us/step - loss: 0.0281 - accuracy: 0.0000e+00 - val_loss: 0.0278 - val_accuracy: 0.0500\n",
            "Epoch 54/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0281 - accuracy: 0.0000e+00 - val_loss: 0.0279 - val_accuracy: 0.0500\n",
            "Epoch 55/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0281 - accuracy: 0.0000e+00 - val_loss: 0.0278 - val_accuracy: 0.0500\n",
            "Epoch 56/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0280 - accuracy: 0.0000e+00 - val_loss: 0.0277 - val_accuracy: 0.0500\n",
            "Epoch 57/600\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0280 - accuracy: 0.0000e+00 - val_loss: 0.0276 - val_accuracy: 0.0500\n",
            "Epoch 58/600\n",
            "80/80 [==============================] - 0s 241us/step - loss: 0.0280 - accuracy: 0.0000e+00 - val_loss: 0.0276 - val_accuracy: 0.0500\n",
            "Epoch 59/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0280 - accuracy: 0.0000e+00 - val_loss: 0.0275 - val_accuracy: 0.0500\n",
            "Epoch 60/600\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0279 - accuracy: 0.0000e+00 - val_loss: 0.0275 - val_accuracy: 0.0500\n",
            "Epoch 61/600\n",
            "80/80 [==============================] - 0s 183us/step - loss: 0.0279 - accuracy: 0.0000e+00 - val_loss: 0.0275 - val_accuracy: 0.0500\n",
            "Epoch 62/600\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0279 - accuracy: 0.0000e+00 - val_loss: 0.0276 - val_accuracy: 0.0500\n",
            "Epoch 63/600\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0279 - accuracy: 0.0000e+00 - val_loss: 0.0278 - val_accuracy: 0.0500\n",
            "Epoch 64/600\n",
            "80/80 [==============================] - 0s 248us/step - loss: 0.0278 - accuracy: 0.0000e+00 - val_loss: 0.0276 - val_accuracy: 0.0500\n",
            "Epoch 65/600\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0278 - accuracy: 0.0000e+00 - val_loss: 0.0276 - val_accuracy: 0.0500\n",
            "Epoch 66/600\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0278 - accuracy: 0.0000e+00 - val_loss: 0.0275 - val_accuracy: 0.0500\n",
            "Epoch 67/600\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0278 - accuracy: 0.0000e+00 - val_loss: 0.0274 - val_accuracy: 0.0500\n",
            "Epoch 68/600\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0277 - accuracy: 0.0000e+00 - val_loss: 0.0275 - val_accuracy: 0.0500\n",
            "Epoch 69/600\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0277 - accuracy: 0.0000e+00 - val_loss: 0.0276 - val_accuracy: 0.0500\n",
            "Epoch 70/600\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0277 - accuracy: 0.0000e+00 - val_loss: 0.0275 - val_accuracy: 0.0500\n",
            "Epoch 71/600\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0276 - accuracy: 0.0000e+00 - val_loss: 0.0274 - val_accuracy: 0.0500\n",
            "Epoch 72/600\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0276 - accuracy: 0.0000e+00 - val_loss: 0.0272 - val_accuracy: 0.0500\n",
            "Epoch 73/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0276 - accuracy: 0.0000e+00 - val_loss: 0.0272 - val_accuracy: 0.0500\n",
            "Epoch 74/600\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0276 - accuracy: 0.0000e+00 - val_loss: 0.0273 - val_accuracy: 0.0500\n",
            "Epoch 75/600\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0276 - accuracy: 0.0000e+00 - val_loss: 0.0273 - val_accuracy: 0.0500\n",
            "Epoch 76/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0275 - accuracy: 0.0000e+00 - val_loss: 0.0275 - val_accuracy: 0.0500\n",
            "Epoch 77/600\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0275 - accuracy: 0.0000e+00 - val_loss: 0.0277 - val_accuracy: 0.0500\n",
            "Epoch 78/600\n",
            "80/80 [==============================] - 0s 268us/step - loss: 0.0275 - accuracy: 0.0000e+00 - val_loss: 0.0275 - val_accuracy: 0.0500\n",
            "Epoch 79/600\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0274 - accuracy: 0.0000e+00 - val_loss: 0.0275 - val_accuracy: 0.0500\n",
            "Epoch 80/600\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0274 - accuracy: 0.0000e+00 - val_loss: 0.0274 - val_accuracy: 0.0500\n",
            "Epoch 81/600\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0274 - accuracy: 0.0000e+00 - val_loss: 0.0273 - val_accuracy: 0.0500\n",
            "Epoch 82/600\n",
            "80/80 [==============================] - 0s 170us/step - loss: 0.0274 - accuracy: 0.0000e+00 - val_loss: 0.0272 - val_accuracy: 0.0500\n",
            "Epoch 83/600\n",
            "80/80 [==============================] - 0s 164us/step - loss: 0.0273 - accuracy: 0.0000e+00 - val_loss: 0.0274 - val_accuracy: 0.0500\n",
            "Epoch 84/600\n",
            "80/80 [==============================] - 0s 228us/step - loss: 0.0273 - accuracy: 0.0000e+00 - val_loss: 0.0276 - val_accuracy: 0.0500\n",
            "Epoch 85/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0273 - accuracy: 0.0000e+00 - val_loss: 0.0278 - val_accuracy: 0.0500\n",
            "Epoch 86/600\n",
            "80/80 [==============================] - 0s 176us/step - loss: 0.0273 - accuracy: 0.0000e+00 - val_loss: 0.0276 - val_accuracy: 0.0500\n",
            "Epoch 87/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0273 - accuracy: 0.0000e+00 - val_loss: 0.0273 - val_accuracy: 0.0500\n",
            "Epoch 88/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0272 - accuracy: 0.0000e+00 - val_loss: 0.0271 - val_accuracy: 0.0500\n",
            "Epoch 89/600\n",
            "80/80 [==============================] - 0s 185us/step - loss: 0.0272 - accuracy: 0.0000e+00 - val_loss: 0.0270 - val_accuracy: 0.0500\n",
            "Epoch 90/600\n",
            "80/80 [==============================] - 0s 185us/step - loss: 0.0272 - accuracy: 0.0000e+00 - val_loss: 0.0269 - val_accuracy: 0.0500\n",
            "Epoch 91/600\n",
            "80/80 [==============================] - 0s 185us/step - loss: 0.0272 - accuracy: 0.0000e+00 - val_loss: 0.0271 - val_accuracy: 0.0500\n",
            "Epoch 92/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0271 - accuracy: 0.0000e+00 - val_loss: 0.0274 - val_accuracy: 0.0500\n",
            "Epoch 93/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0272 - accuracy: 0.0000e+00 - val_loss: 0.0275 - val_accuracy: 0.0500\n",
            "Epoch 94/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0271 - accuracy: 0.0000e+00 - val_loss: 0.0273 - val_accuracy: 0.0500\n",
            "Epoch 95/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0271 - accuracy: 0.0000e+00 - val_loss: 0.0272 - val_accuracy: 0.0500\n",
            "Epoch 96/600\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0270 - accuracy: 0.0000e+00 - val_loss: 0.0272 - val_accuracy: 0.0500\n",
            "Epoch 97/600\n",
            "80/80 [==============================] - 0s 181us/step - loss: 0.0270 - accuracy: 0.0000e+00 - val_loss: 0.0272 - val_accuracy: 0.0500\n",
            "Epoch 98/600\n",
            "80/80 [==============================] - 0s 168us/step - loss: 0.0270 - accuracy: 0.0000e+00 - val_loss: 0.0273 - val_accuracy: 0.0500\n",
            "Epoch 99/600\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0270 - accuracy: 0.0000e+00 - val_loss: 0.0274 - val_accuracy: 0.0500\n",
            "Epoch 100/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0270 - accuracy: 0.0000e+00 - val_loss: 0.0274 - val_accuracy: 0.0500\n",
            "Epoch 101/600\n",
            "80/80 [==============================] - 0s 161us/step - loss: 0.0269 - accuracy: 0.0000e+00 - val_loss: 0.0273 - val_accuracy: 0.0500\n",
            "Epoch 102/600\n",
            "80/80 [==============================] - 0s 172us/step - loss: 0.0269 - accuracy: 0.0000e+00 - val_loss: 0.0272 - val_accuracy: 0.0500\n",
            "Epoch 103/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0269 - accuracy: 0.0000e+00 - val_loss: 0.0271 - val_accuracy: 0.0500\n",
            "Epoch 104/600\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0269 - accuracy: 0.0000e+00 - val_loss: 0.0269 - val_accuracy: 0.0500\n",
            "Epoch 105/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0268 - accuracy: 0.0000e+00 - val_loss: 0.0270 - val_accuracy: 0.0500\n",
            "Epoch 106/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0268 - accuracy: 0.0000e+00 - val_loss: 0.0270 - val_accuracy: 0.0500\n",
            "Epoch 107/600\n",
            "80/80 [==============================] - 0s 165us/step - loss: 0.0268 - accuracy: 0.0000e+00 - val_loss: 0.0271 - val_accuracy: 0.0500\n",
            "Epoch 108/600\n",
            "80/80 [==============================] - 0s 174us/step - loss: 0.0268 - accuracy: 0.0000e+00 - val_loss: 0.0271 - val_accuracy: 0.0500\n",
            "Epoch 109/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0268 - accuracy: 0.0000e+00 - val_loss: 0.0270 - val_accuracy: 0.0500\n",
            "Epoch 110/600\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0267 - accuracy: 0.0000e+00 - val_loss: 0.0268 - val_accuracy: 0.0500\n",
            "Epoch 111/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0267 - accuracy: 0.0000e+00 - val_loss: 0.0267 - val_accuracy: 0.0500\n",
            "Epoch 112/600\n",
            "80/80 [==============================] - 0s 168us/step - loss: 0.0267 - accuracy: 0.0000e+00 - val_loss: 0.0268 - val_accuracy: 0.0500\n",
            "Epoch 113/600\n",
            "80/80 [==============================] - 0s 174us/step - loss: 0.0267 - accuracy: 0.0000e+00 - val_loss: 0.0267 - val_accuracy: 0.0500\n",
            "Epoch 114/600\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0266 - accuracy: 0.0000e+00 - val_loss: 0.0269 - val_accuracy: 0.0500\n",
            "Epoch 115/600\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0266 - accuracy: 0.0000e+00 - val_loss: 0.0270 - val_accuracy: 0.0500\n",
            "Epoch 116/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0266 - accuracy: 0.0000e+00 - val_loss: 0.0270 - val_accuracy: 0.0500\n",
            "Epoch 117/600\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0266 - accuracy: 0.0000e+00 - val_loss: 0.0269 - val_accuracy: 0.0500\n",
            "Epoch 118/600\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0266 - accuracy: 0.0000e+00 - val_loss: 0.0268 - val_accuracy: 0.0500\n",
            "Epoch 119/600\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0265 - accuracy: 0.0000e+00 - val_loss: 0.0267 - val_accuracy: 0.0500\n",
            "Epoch 120/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0265 - accuracy: 0.0000e+00 - val_loss: 0.0267 - val_accuracy: 0.0500\n",
            "Epoch 121/600\n",
            "80/80 [==============================] - 0s 176us/step - loss: 0.0265 - accuracy: 0.0000e+00 - val_loss: 0.0267 - val_accuracy: 0.0500\n",
            "Epoch 122/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0265 - accuracy: 0.0000e+00 - val_loss: 0.0268 - val_accuracy: 0.0500\n",
            "Epoch 123/600\n",
            "80/80 [==============================] - 0s 185us/step - loss: 0.0265 - accuracy: 0.0000e+00 - val_loss: 0.0270 - val_accuracy: 0.0500\n",
            "Epoch 124/600\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0265 - accuracy: 0.0000e+00 - val_loss: 0.0270 - val_accuracy: 0.0500\n",
            "Epoch 125/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0265 - accuracy: 0.0000e+00 - val_loss: 0.0269 - val_accuracy: 0.0500\n",
            "Epoch 126/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0264 - accuracy: 0.0000e+00 - val_loss: 0.0269 - val_accuracy: 0.0500\n",
            "Epoch 127/600\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0264 - accuracy: 0.0000e+00 - val_loss: 0.0268 - val_accuracy: 0.0500\n",
            "Epoch 128/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0264 - accuracy: 0.0000e+00 - val_loss: 0.0266 - val_accuracy: 0.0500\n",
            "Epoch 129/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0263 - accuracy: 0.0000e+00 - val_loss: 0.0266 - val_accuracy: 0.0500\n",
            "Epoch 130/600\n",
            "80/80 [==============================] - 0s 177us/step - loss: 0.0263 - accuracy: 0.0000e+00 - val_loss: 0.0265 - val_accuracy: 0.0500\n",
            "Epoch 131/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0263 - accuracy: 0.0000e+00 - val_loss: 0.0265 - val_accuracy: 0.0500\n",
            "Epoch 132/600\n",
            "80/80 [==============================] - 0s 183us/step - loss: 0.0263 - accuracy: 0.0000e+00 - val_loss: 0.0265 - val_accuracy: 0.0500\n",
            "Epoch 133/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0262 - accuracy: 0.0000e+00 - val_loss: 0.0265 - val_accuracy: 0.0500\n",
            "Epoch 134/600\n",
            "80/80 [==============================] - 0s 169us/step - loss: 0.0262 - accuracy: 0.0000e+00 - val_loss: 0.0265 - val_accuracy: 0.0500\n",
            "Epoch 135/600\n",
            "80/80 [==============================] - 0s 163us/step - loss: 0.0262 - accuracy: 0.0000e+00 - val_loss: 0.0265 - val_accuracy: 0.0500\n",
            "Epoch 136/600\n",
            "80/80 [==============================] - 0s 152us/step - loss: 0.0262 - accuracy: 0.0000e+00 - val_loss: 0.0265 - val_accuracy: 0.0500\n",
            "Epoch 137/600\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.0262 - accuracy: 0.0000e+00 - val_loss: 0.0265 - val_accuracy: 0.0500\n",
            "Epoch 138/600\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0261 - accuracy: 0.0000e+00 - val_loss: 0.0264 - val_accuracy: 0.0500\n",
            "Epoch 139/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0261 - accuracy: 0.0000e+00 - val_loss: 0.0263 - val_accuracy: 0.0500\n",
            "Epoch 140/600\n",
            "80/80 [==============================] - 0s 178us/step - loss: 0.0261 - accuracy: 0.0000e+00 - val_loss: 0.0263 - val_accuracy: 0.0500\n",
            "Epoch 141/600\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0261 - accuracy: 0.0000e+00 - val_loss: 0.0261 - val_accuracy: 0.0500\n",
            "Epoch 142/600\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0261 - accuracy: 0.0000e+00 - val_loss: 0.0260 - val_accuracy: 0.0500\n",
            "Epoch 143/600\n",
            "80/80 [==============================] - 0s 181us/step - loss: 0.0261 - accuracy: 0.0000e+00 - val_loss: 0.0259 - val_accuracy: 0.0500\n",
            "Epoch 144/600\n",
            "80/80 [==============================] - 0s 182us/step - loss: 0.0261 - accuracy: 0.0000e+00 - val_loss: 0.0259 - val_accuracy: 0.0500\n",
            "Epoch 145/600\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0260 - accuracy: 0.0000e+00 - val_loss: 0.0262 - val_accuracy: 0.0500\n",
            "Epoch 146/600\n",
            "80/80 [==============================] - 0s 162us/step - loss: 0.0260 - accuracy: 0.0000e+00 - val_loss: 0.0264 - val_accuracy: 0.0500\n",
            "Epoch 147/600\n",
            "80/80 [==============================] - 0s 167us/step - loss: 0.0260 - accuracy: 0.0000e+00 - val_loss: 0.0265 - val_accuracy: 0.0500\n",
            "Epoch 148/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0260 - accuracy: 0.0000e+00 - val_loss: 0.0263 - val_accuracy: 0.0500\n",
            "Epoch 149/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0259 - accuracy: 0.0000e+00 - val_loss: 0.0260 - val_accuracy: 0.0500\n",
            "Epoch 150/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0259 - accuracy: 0.0000e+00 - val_loss: 0.0259 - val_accuracy: 0.0500\n",
            "Epoch 151/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0259 - accuracy: 0.0000e+00 - val_loss: 0.0260 - val_accuracy: 0.0500\n",
            "Epoch 152/600\n",
            "80/80 [==============================] - 0s 167us/step - loss: 0.0259 - accuracy: 0.0000e+00 - val_loss: 0.0260 - val_accuracy: 0.0500\n",
            "Epoch 153/600\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0258 - accuracy: 0.0000e+00 - val_loss: 0.0262 - val_accuracy: 0.0500\n",
            "Epoch 154/600\n",
            "80/80 [==============================] - 0s 163us/step - loss: 0.0259 - accuracy: 0.0000e+00 - val_loss: 0.0263 - val_accuracy: 0.0500\n",
            "Epoch 155/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0258 - accuracy: 0.0000e+00 - val_loss: 0.0262 - val_accuracy: 0.0500\n",
            "Epoch 156/600\n",
            "80/80 [==============================] - 0s 179us/step - loss: 0.0258 - accuracy: 0.0000e+00 - val_loss: 0.0261 - val_accuracy: 0.0500\n",
            "Epoch 157/600\n",
            "80/80 [==============================] - 0s 182us/step - loss: 0.0258 - accuracy: 0.0000e+00 - val_loss: 0.0261 - val_accuracy: 0.0500\n",
            "Epoch 158/600\n",
            "80/80 [==============================] - 0s 176us/step - loss: 0.0258 - accuracy: 0.0000e+00 - val_loss: 0.0260 - val_accuracy: 0.0500\n",
            "Epoch 159/600\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0258 - accuracy: 0.0000e+00 - val_loss: 0.0261 - val_accuracy: 0.0500\n",
            "Epoch 160/600\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0257 - accuracy: 0.0000e+00 - val_loss: 0.0261 - val_accuracy: 0.0500\n",
            "Epoch 161/600\n",
            "80/80 [==============================] - 0s 216us/step - loss: 0.0257 - accuracy: 0.0000e+00 - val_loss: 0.0262 - val_accuracy: 0.0500\n",
            "Epoch 162/600\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0257 - accuracy: 0.0000e+00 - val_loss: 0.0262 - val_accuracy: 0.0500\n",
            "Epoch 163/600\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0257 - accuracy: 0.0000e+00 - val_loss: 0.0261 - val_accuracy: 0.0500\n",
            "Epoch 164/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0256 - accuracy: 0.0000e+00 - val_loss: 0.0261 - val_accuracy: 0.0500\n",
            "Epoch 165/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0256 - accuracy: 0.0000e+00 - val_loss: 0.0261 - val_accuracy: 0.0500\n",
            "Epoch 166/600\n",
            "80/80 [==============================] - 0s 178us/step - loss: 0.0256 - accuracy: 0.0000e+00 - val_loss: 0.0261 - val_accuracy: 0.0500\n",
            "Epoch 167/600\n",
            "80/80 [==============================] - 0s 161us/step - loss: 0.0256 - accuracy: 0.0000e+00 - val_loss: 0.0259 - val_accuracy: 0.0500\n",
            "Epoch 168/600\n",
            "80/80 [==============================] - 0s 167us/step - loss: 0.0256 - accuracy: 0.0000e+00 - val_loss: 0.0258 - val_accuracy: 0.0500\n",
            "Epoch 169/600\n",
            "80/80 [==============================] - 0s 165us/step - loss: 0.0256 - accuracy: 0.0000e+00 - val_loss: 0.0258 - val_accuracy: 0.0500\n",
            "Epoch 170/600\n",
            "80/80 [==============================] - 0s 279us/step - loss: 0.0255 - accuracy: 0.0000e+00 - val_loss: 0.0258 - val_accuracy: 0.0500\n",
            "Epoch 171/600\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0256 - accuracy: 0.0000e+00 - val_loss: 0.0259 - val_accuracy: 0.0500\n",
            "Epoch 172/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0255 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 173/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0255 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 174/600\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0254 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 175/600\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0254 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0500\n",
            "Epoch 176/600\n",
            "80/80 [==============================] - 0s 183us/step - loss: 0.0254 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 177/600\n",
            "80/80 [==============================] - 0s 150us/step - loss: 0.0254 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 178/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0254 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0500\n",
            "Epoch 179/600\n",
            "80/80 [==============================] - 0s 173us/step - loss: 0.0254 - accuracy: 0.0000e+00 - val_loss: 0.0255 - val_accuracy: 0.0500\n",
            "Epoch 180/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0253 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0500\n",
            "Epoch 181/600\n",
            "80/80 [==============================] - 0s 182us/step - loss: 0.0253 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0500\n",
            "Epoch 182/600\n",
            "80/80 [==============================] - 0s 164us/step - loss: 0.0253 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 183/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0253 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 184/600\n",
            "80/80 [==============================] - 0s 179us/step - loss: 0.0253 - accuracy: 0.0000e+00 - val_loss: 0.0259 - val_accuracy: 0.0500\n",
            "Epoch 185/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0253 - accuracy: 0.0000e+00 - val_loss: 0.0260 - val_accuracy: 0.0500\n",
            "Epoch 186/600\n",
            "80/80 [==============================] - 0s 183us/step - loss: 0.0253 - accuracy: 0.0000e+00 - val_loss: 0.0260 - val_accuracy: 0.0500\n",
            "Epoch 187/600\n",
            "80/80 [==============================] - 0s 185us/step - loss: 0.0253 - accuracy: 0.0000e+00 - val_loss: 0.0259 - val_accuracy: 0.0500\n",
            "Epoch 188/600\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0253 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0500\n",
            "Epoch 189/600\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0252 - accuracy: 0.0000e+00 - val_loss: 0.0255 - val_accuracy: 0.0500\n",
            "Epoch 190/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0252 - accuracy: 0.0000e+00 - val_loss: 0.0255 - val_accuracy: 0.0500\n",
            "Epoch 191/600\n",
            "80/80 [==============================] - 0s 181us/step - loss: 0.0251 - accuracy: 0.0000e+00 - val_loss: 0.0254 - val_accuracy: 0.0500\n",
            "Epoch 192/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0252 - accuracy: 0.0000e+00 - val_loss: 0.0254 - val_accuracy: 0.0500\n",
            "Epoch 193/600\n",
            "80/80 [==============================] - 0s 173us/step - loss: 0.0251 - accuracy: 0.0000e+00 - val_loss: 0.0255 - val_accuracy: 0.0500\n",
            "Epoch 194/600\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0251 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0500\n",
            "Epoch 195/600\n",
            "80/80 [==============================] - 0s 166us/step - loss: 0.0251 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0500\n",
            "Epoch 196/600\n",
            "80/80 [==============================] - 0s 163us/step - loss: 0.0251 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 197/600\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0250 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 198/600\n",
            "80/80 [==============================] - 0s 166us/step - loss: 0.0251 - accuracy: 0.0000e+00 - val_loss: 0.0258 - val_accuracy: 0.0500\n",
            "Epoch 199/600\n",
            "80/80 [==============================] - 0s 183us/step - loss: 0.0250 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 200/600\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0250 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0500\n",
            "Epoch 201/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0250 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0500\n",
            "Epoch 202/600\n",
            "80/80 [==============================] - 0s 173us/step - loss: 0.0250 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0500\n",
            "Epoch 203/600\n",
            "80/80 [==============================] - 0s 170us/step - loss: 0.0249 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 204/600\n",
            "80/80 [==============================] - 0s 183us/step - loss: 0.0249 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0500\n",
            "Epoch 205/600\n",
            "80/80 [==============================] - 0s 179us/step - loss: 0.0249 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 206/600\n",
            "80/80 [==============================] - 0s 166us/step - loss: 0.0249 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0500\n",
            "Epoch 207/600\n",
            "80/80 [==============================] - 0s 176us/step - loss: 0.0249 - accuracy: 0.0000e+00 - val_loss: 0.0256 - val_accuracy: 0.0500\n",
            "Epoch 208/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0249 - accuracy: 0.0000e+00 - val_loss: 0.0255 - val_accuracy: 0.0500\n",
            "Epoch 209/600\n",
            "80/80 [==============================] - 0s 179us/step - loss: 0.0248 - accuracy: 0.0000e+00 - val_loss: 0.0254 - val_accuracy: 0.0500\n",
            "Epoch 210/600\n",
            "80/80 [==============================] - 0s 169us/step - loss: 0.0249 - accuracy: 0.0000e+00 - val_loss: 0.0254 - val_accuracy: 0.0500\n",
            "Epoch 211/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0248 - accuracy: 0.0000e+00 - val_loss: 0.0252 - val_accuracy: 0.0500\n",
            "Epoch 212/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0248 - accuracy: 0.0000e+00 - val_loss: 0.0252 - val_accuracy: 0.0500\n",
            "Epoch 213/600\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0248 - accuracy: 0.0000e+00 - val_loss: 0.0252 - val_accuracy: 0.0500\n",
            "Epoch 214/600\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0247 - accuracy: 0.0000e+00 - val_loss: 0.0251 - val_accuracy: 0.0500\n",
            "Epoch 215/600\n",
            "80/80 [==============================] - 0s 175us/step - loss: 0.0247 - accuracy: 0.0000e+00 - val_loss: 0.0251 - val_accuracy: 0.0500\n",
            "Epoch 216/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0247 - accuracy: 0.0000e+00 - val_loss: 0.0251 - val_accuracy: 0.0500\n",
            "Epoch 217/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0247 - accuracy: 0.0000e+00 - val_loss: 0.0251 - val_accuracy: 0.0500\n",
            "Epoch 218/600\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0247 - accuracy: 0.0000e+00 - val_loss: 0.0251 - val_accuracy: 0.0500\n",
            "Epoch 219/600\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0247 - accuracy: 0.0000e+00 - val_loss: 0.0251 - val_accuracy: 0.0500\n",
            "Epoch 220/600\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0246 - accuracy: 0.0000e+00 - val_loss: 0.0251 - val_accuracy: 0.0500\n",
            "Epoch 221/600\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0246 - accuracy: 0.0000e+00 - val_loss: 0.0250 - val_accuracy: 0.0500\n",
            "Epoch 222/600\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0246 - accuracy: 0.0000e+00 - val_loss: 0.0250 - val_accuracy: 0.0500\n",
            "Epoch 223/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0246 - accuracy: 0.0000e+00 - val_loss: 0.0249 - val_accuracy: 0.0500\n",
            "Epoch 224/600\n",
            "80/80 [==============================] - 0s 235us/step - loss: 0.0246 - accuracy: 0.0000e+00 - val_loss: 0.0249 - val_accuracy: 0.0500\n",
            "Epoch 225/600\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0246 - accuracy: 0.0000e+00 - val_loss: 0.0249 - val_accuracy: 0.0500\n",
            "Epoch 226/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0245 - accuracy: 0.0000e+00 - val_loss: 0.0249 - val_accuracy: 0.0500\n",
            "Epoch 227/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0245 - accuracy: 0.0000e+00 - val_loss: 0.0248 - val_accuracy: 0.0500\n",
            "Epoch 228/600\n",
            "80/80 [==============================] - 0s 178us/step - loss: 0.0245 - accuracy: 0.0000e+00 - val_loss: 0.0248 - val_accuracy: 0.0500\n",
            "Epoch 229/600\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0245 - accuracy: 0.0000e+00 - val_loss: 0.0249 - val_accuracy: 0.0500\n",
            "Epoch 230/600\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0245 - accuracy: 0.0000e+00 - val_loss: 0.0249 - val_accuracy: 0.0500\n",
            "Epoch 231/600\n",
            "80/80 [==============================] - 0s 378us/step - loss: 0.0244 - accuracy: 0.0000e+00 - val_loss: 0.0248 - val_accuracy: 0.0500\n",
            "Epoch 232/600\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0245 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 233/600\n",
            "80/80 [==============================] - 0s 185us/step - loss: 0.0245 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 234/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0245 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 235/600\n",
            "80/80 [==============================] - 0s 179us/step - loss: 0.0244 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 236/600\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0244 - accuracy: 0.0000e+00 - val_loss: 0.0248 - val_accuracy: 0.0500\n",
            "Epoch 237/600\n",
            "80/80 [==============================] - 0s 181us/step - loss: 0.0244 - accuracy: 0.0000e+00 - val_loss: 0.0250 - val_accuracy: 0.0500\n",
            "Epoch 238/600\n",
            "80/80 [==============================] - 0s 178us/step - loss: 0.0244 - accuracy: 0.0000e+00 - val_loss: 0.0251 - val_accuracy: 0.0500\n",
            "Epoch 239/600\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0243 - accuracy: 0.0000e+00 - val_loss: 0.0250 - val_accuracy: 0.0500\n",
            "Epoch 240/600\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0243 - accuracy: 0.0000e+00 - val_loss: 0.0248 - val_accuracy: 0.0500\n",
            "Epoch 241/600\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0243 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 242/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0243 - accuracy: 0.0000e+00 - val_loss: 0.0246 - val_accuracy: 0.0500\n",
            "Epoch 243/600\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0243 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 244/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0243 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 245/600\n",
            "80/80 [==============================] - 0s 182us/step - loss: 0.0243 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 246/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0242 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 247/600\n",
            "80/80 [==============================] - 0s 169us/step - loss: 0.0243 - accuracy: 0.0000e+00 - val_loss: 0.0248 - val_accuracy: 0.0500\n",
            "Epoch 248/600\n",
            "80/80 [==============================] - 0s 177us/step - loss: 0.0242 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 249/600\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0242 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 250/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0242 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 251/600\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0241 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 252/600\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0241 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 253/600\n",
            "80/80 [==============================] - 0s 183us/step - loss: 0.0241 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 254/600\n",
            "80/80 [==============================] - 0s 171us/step - loss: 0.0241 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 255/600\n",
            "80/80 [==============================] - 0s 169us/step - loss: 0.0241 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 256/600\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0241 - accuracy: 0.0000e+00 - val_loss: 0.0246 - val_accuracy: 0.0500\n",
            "Epoch 257/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0241 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 258/600\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0240 - accuracy: 0.0000e+00 - val_loss: 0.0246 - val_accuracy: 0.0500\n",
            "Epoch 259/600\n",
            "80/80 [==============================] - 0s 178us/step - loss: 0.0240 - accuracy: 0.0000e+00 - val_loss: 0.0246 - val_accuracy: 0.0500\n",
            "Epoch 260/600\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0240 - accuracy: 0.0000e+00 - val_loss: 0.0245 - val_accuracy: 0.0500\n",
            "Epoch 261/600\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0240 - accuracy: 0.0000e+00 - val_loss: 0.0246 - val_accuracy: 0.0500\n",
            "Epoch 262/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0240 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 263/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0240 - accuracy: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.0500\n",
            "Epoch 264/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0239 - accuracy: 0.0000e+00 - val_loss: 0.0245 - val_accuracy: 0.0500\n",
            "Epoch 265/600\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0239 - accuracy: 0.0000e+00 - val_loss: 0.0244 - val_accuracy: 0.0500\n",
            "Epoch 266/600\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0239 - accuracy: 0.0000e+00 - val_loss: 0.0245 - val_accuracy: 0.0500\n",
            "Epoch 267/600\n",
            "80/80 [==============================] - 0s 294us/step - loss: 0.0239 - accuracy: 0.0000e+00 - val_loss: 0.0245 - val_accuracy: 0.0500\n",
            "Epoch 268/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0239 - accuracy: 0.0000e+00 - val_loss: 0.0245 - val_accuracy: 0.0500\n",
            "Epoch 269/600\n",
            "80/80 [==============================] - 0s 176us/step - loss: 0.0239 - accuracy: 0.0000e+00 - val_loss: 0.0244 - val_accuracy: 0.0500\n",
            "Epoch 270/600\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0238 - accuracy: 0.0000e+00 - val_loss: 0.0245 - val_accuracy: 0.0500\n",
            "Epoch 271/600\n",
            "80/80 [==============================] - 0s 234us/step - loss: 0.0238 - accuracy: 0.0000e+00 - val_loss: 0.0248 - val_accuracy: 0.0500\n",
            "Epoch 272/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0239 - accuracy: 0.0000e+00 - val_loss: 0.0248 - val_accuracy: 0.0500\n",
            "Epoch 273/600\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0238 - accuracy: 0.0000e+00 - val_loss: 0.0245 - val_accuracy: 0.0500\n",
            "Epoch 274/600\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0238 - accuracy: 0.0000e+00 - val_loss: 0.0244 - val_accuracy: 0.0500\n",
            "Epoch 275/600\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0238 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0500\n",
            "Epoch 276/600\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0238 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0500\n",
            "Epoch 277/600\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0237 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0500\n",
            "Epoch 278/600\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.0237 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0500\n",
            "Epoch 279/600\n",
            "80/80 [==============================] - 0s 370us/step - loss: 0.0237 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0500\n",
            "Epoch 280/600\n",
            "80/80 [==============================] - 0s 243us/step - loss: 0.0237 - accuracy: 0.0000e+00 - val_loss: 0.0242 - val_accuracy: 0.0500\n",
            "Epoch 281/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0237 - accuracy: 0.0000e+00 - val_loss: 0.0242 - val_accuracy: 0.0500\n",
            "Epoch 282/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0237 - accuracy: 0.0000e+00 - val_loss: 0.0242 - val_accuracy: 0.0500\n",
            "Epoch 283/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0236 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0500\n",
            "Epoch 284/600\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0236 - accuracy: 0.0000e+00 - val_loss: 0.0244 - val_accuracy: 0.0500\n",
            "Epoch 285/600\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0236 - accuracy: 0.0000e+00 - val_loss: 0.0245 - val_accuracy: 0.0500\n",
            "Epoch 286/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0236 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0500\n",
            "Epoch 287/600\n",
            "80/80 [==============================] - 0s 236us/step - loss: 0.0236 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0500\n",
            "Epoch 288/600\n",
            "80/80 [==============================] - 0s 250us/step - loss: 0.0236 - accuracy: 0.0000e+00 - val_loss: 0.0244 - val_accuracy: 0.0500\n",
            "Epoch 289/600\n",
            "80/80 [==============================] - 0s 246us/step - loss: 0.0235 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0500\n",
            "Epoch 290/600\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0235 - accuracy: 0.0000e+00 - val_loss: 0.0242 - val_accuracy: 0.0500\n",
            "Epoch 291/600\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0235 - accuracy: 0.0000e+00 - val_loss: 0.0241 - val_accuracy: 0.0500\n",
            "Epoch 292/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0235 - accuracy: 0.0000e+00 - val_loss: 0.0241 - val_accuracy: 0.0500\n",
            "Epoch 293/600\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0235 - accuracy: 0.0000e+00 - val_loss: 0.0241 - val_accuracy: 0.0500\n",
            "Epoch 294/600\n",
            "80/80 [==============================] - 0s 174us/step - loss: 0.0235 - accuracy: 0.0000e+00 - val_loss: 0.0242 - val_accuracy: 0.0500\n",
            "Epoch 295/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0235 - accuracy: 0.0000e+00 - val_loss: 0.0242 - val_accuracy: 0.0500\n",
            "Epoch 296/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0235 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0500\n",
            "Epoch 297/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0235 - accuracy: 0.0000e+00 - val_loss: 0.0242 - val_accuracy: 0.0500\n",
            "Epoch 298/600\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0234 - accuracy: 0.0000e+00 - val_loss: 0.0241 - val_accuracy: 0.0500\n",
            "Epoch 299/600\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0234 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 300/600\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0234 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 301/600\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0234 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 302/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0233 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 303/600\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0233 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 304/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0233 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 305/600\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0233 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 306/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0233 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 307/600\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0233 - accuracy: 0.0000e+00 - val_loss: 0.0242 - val_accuracy: 0.0500\n",
            "Epoch 308/600\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0233 - accuracy: 0.0000e+00 - val_loss: 0.0241 - val_accuracy: 0.0500\n",
            "Epoch 309/600\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 310/600\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0500\n",
            "Epoch 311/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 312/600\n",
            "80/80 [==============================] - 0s 288us/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 313/600\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 314/600\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0500\n",
            "Epoch 315/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0238 - val_accuracy: 0.0500\n",
            "Epoch 316/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0231 - accuracy: 0.0000e+00 - val_loss: 0.0238 - val_accuracy: 0.0500\n",
            "Epoch 317/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0231 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0500\n",
            "Epoch 318/600\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0231 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 319/600\n",
            "80/80 [==============================] - 0s 179us/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0241 - val_accuracy: 0.0500\n",
            "Epoch 320/600\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0231 - accuracy: 0.0000e+00 - val_loss: 0.0241 - val_accuracy: 0.0500\n",
            "Epoch 321/600\n",
            "80/80 [==============================] - 0s 185us/step - loss: 0.0231 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 322/600\n",
            "80/80 [==============================] - 0s 222us/step - loss: 0.0231 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0500\n",
            "Epoch 323/600\n",
            "80/80 [==============================] - 0s 272us/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 0.0238 - val_accuracy: 0.0500\n",
            "Epoch 324/600\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 0.0238 - val_accuracy: 0.0500\n",
            "Epoch 325/600\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0500\n",
            "Epoch 326/600\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 0.0240 - val_accuracy: 0.0500\n",
            "Epoch 327/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0500\n",
            "Epoch 328/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 0.0241 - val_accuracy: 0.0500\n",
            "Epoch 329/600\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0500\n",
            "Epoch 330/600\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0229 - accuracy: 0.0000e+00 - val_loss: 0.0237 - val_accuracy: 0.0500\n",
            "Epoch 331/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0231 - accuracy: 0.0000e+00 - val_loss: 0.0237 - val_accuracy: 0.0500\n",
            "Epoch 332/600\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 0.0237 - val_accuracy: 0.0500\n",
            "Epoch 333/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 0.0237 - val_accuracy: 0.0500\n",
            "Epoch 334/600\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0229 - accuracy: 0.0000e+00 - val_loss: 0.0238 - val_accuracy: 0.0500\n",
            "Epoch 335/600\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0229 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0500\n",
            "Epoch 336/600\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0229 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0500\n",
            "Epoch 337/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0229 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0500\n",
            "Epoch 338/600\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0228 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0500\n",
            "Epoch 339/600\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0228 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0500\n",
            "Epoch 340/600\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0228 - accuracy: 0.0000e+00 - val_loss: 0.0239 - val_accuracy: 0.0500\n",
            "Epoch 341/600\n",
            "80/80 [==============================] - 0s 273us/step - loss: 0.0228 - accuracy: 0.0000e+00 - val_loss: 0.0237 - val_accuracy: 0.0500\n",
            "Epoch 342/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0228 - accuracy: 0.0000e+00 - val_loss: 0.0237 - val_accuracy: 0.0500\n",
            "Epoch 343/600\n",
            "80/80 [==============================] - 0s 211us/step - loss: 0.0227 - accuracy: 0.0000e+00 - val_loss: 0.0237 - val_accuracy: 0.0500\n",
            "Epoch 344/600\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0227 - accuracy: 0.0000e+00 - val_loss: 0.0237 - val_accuracy: 0.0500\n",
            "Epoch 345/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0227 - accuracy: 0.0000e+00 - val_loss: 0.0238 - val_accuracy: 0.0500\n",
            "Epoch 346/600\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0227 - accuracy: 0.0000e+00 - val_loss: 0.0238 - val_accuracy: 0.0500\n",
            "Epoch 347/600\n",
            "80/80 [==============================] - 0s 185us/step - loss: 0.0227 - accuracy: 0.0000e+00 - val_loss: 0.0237 - val_accuracy: 0.0500\n",
            "Epoch 348/600\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0227 - accuracy: 0.0000e+00 - val_loss: 0.0236 - val_accuracy: 0.0500\n",
            "Epoch 349/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0227 - accuracy: 0.0000e+00 - val_loss: 0.0235 - val_accuracy: 0.0500\n",
            "Epoch 350/600\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0227 - accuracy: 0.0000e+00 - val_loss: 0.0235 - val_accuracy: 0.0500\n",
            "Epoch 351/600\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0226 - accuracy: 0.0000e+00 - val_loss: 0.0235 - val_accuracy: 0.0500\n",
            "Epoch 352/600\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0226 - accuracy: 0.0000e+00 - val_loss: 0.0236 - val_accuracy: 0.0500\n",
            "Epoch 353/600\n",
            "80/80 [==============================] - 0s 224us/step - loss: 0.0226 - accuracy: 0.0000e+00 - val_loss: 0.0236 - val_accuracy: 0.0500\n",
            "Epoch 354/600\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0226 - accuracy: 0.0000e+00 - val_loss: 0.0236 - val_accuracy: 0.0500\n",
            "Epoch 355/600\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0226 - accuracy: 0.0000e+00 - val_loss: 0.0235 - val_accuracy: 0.0500\n",
            "Epoch 356/600\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0226 - accuracy: 0.0000e+00 - val_loss: 0.0235 - val_accuracy: 0.0500\n",
            "Epoch 357/600\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0226 - accuracy: 0.0000e+00 - val_loss: 0.0235 - val_accuracy: 0.0500\n",
            "Epoch 358/600\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0226 - accuracy: 0.0000e+00 - val_loss: 0.0236 - val_accuracy: 0.0500\n",
            "Epoch 359/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0225 - accuracy: 0.0000e+00 - val_loss: 0.0236 - val_accuracy: 0.0500\n",
            "Epoch 360/600\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0225 - accuracy: 0.0000e+00 - val_loss: 0.0236 - val_accuracy: 0.0500\n",
            "Epoch 361/600\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0225 - accuracy: 0.0000e+00 - val_loss: 0.0235 - val_accuracy: 0.0500\n",
            "Epoch 362/600\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0225 - accuracy: 0.0000e+00 - val_loss: 0.0234 - val_accuracy: 0.0500\n",
            "Epoch 363/600\n",
            "80/80 [==============================] - 0s 173us/step - loss: 0.0225 - accuracy: 0.0000e+00 - val_loss: 0.0234 - val_accuracy: 0.0500\n",
            "Epoch 364/600\n",
            "80/80 [==============================] - 0s 181us/step - loss: 0.0225 - accuracy: 0.0000e+00 - val_loss: 0.0234 - val_accuracy: 0.0500\n",
            "Epoch 365/600\n",
            "80/80 [==============================] - 0s 175us/step - loss: 0.0225 - accuracy: 0.0000e+00 - val_loss: 0.0234 - val_accuracy: 0.0500\n",
            "Epoch 366/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0224 - accuracy: 0.0000e+00 - val_loss: 0.0234 - val_accuracy: 0.0500\n",
            "Epoch 367/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0224 - accuracy: 0.0000e+00 - val_loss: 0.0234 - val_accuracy: 0.0500\n",
            "Epoch 368/600\n",
            "80/80 [==============================] - 0s 172us/step - loss: 0.0224 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 369/600\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0224 - accuracy: 0.0000e+00 - val_loss: 0.0234 - val_accuracy: 0.0500\n",
            "Epoch 370/600\n",
            "80/80 [==============================] - 0s 233us/step - loss: 0.0224 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 371/600\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0224 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 372/600\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0223 - accuracy: 0.0000e+00 - val_loss: 0.0232 - val_accuracy: 0.0500\n",
            "Epoch 373/600\n",
            "80/80 [==============================] - 0s 183us/step - loss: 0.0224 - accuracy: 0.0000e+00 - val_loss: 0.0232 - val_accuracy: 0.0500\n",
            "Epoch 374/600\n",
            "80/80 [==============================] - 0s 182us/step - loss: 0.0224 - accuracy: 0.0000e+00 - val_loss: 0.0232 - val_accuracy: 0.0500\n",
            "Epoch 375/600\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0224 - accuracy: 0.0000e+00 - val_loss: 0.0232 - val_accuracy: 0.0500\n",
            "Epoch 376/600\n",
            "80/80 [==============================] - 0s 176us/step - loss: 0.0223 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 377/600\n",
            "80/80 [==============================] - 0s 173us/step - loss: 0.0223 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 378/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0223 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 379/600\n",
            "80/80 [==============================] - 0s 170us/step - loss: 0.0223 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 380/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0223 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 381/600\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0222 - accuracy: 0.0000e+00 - val_loss: 0.0232 - val_accuracy: 0.0500\n",
            "Epoch 382/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0223 - accuracy: 0.0000e+00 - val_loss: 0.0231 - val_accuracy: 0.0500\n",
            "Epoch 383/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0222 - accuracy: 0.0000e+00 - val_loss: 0.0232 - val_accuracy: 0.0500\n",
            "Epoch 384/600\n",
            "80/80 [==============================] - 0s 181us/step - loss: 0.0222 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 385/600\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0222 - accuracy: 0.0000e+00 - val_loss: 0.0234 - val_accuracy: 0.0500\n",
            "Epoch 386/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0222 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 387/600\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0222 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 388/600\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0222 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 389/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0221 - accuracy: 0.0000e+00 - val_loss: 0.0232 - val_accuracy: 0.0500\n",
            "Epoch 390/600\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0221 - accuracy: 0.0000e+00 - val_loss: 0.0233 - val_accuracy: 0.0500\n",
            "Epoch 391/600\n",
            "80/80 [==============================] - 0s 185us/step - loss: 0.0221 - accuracy: 0.0000e+00 - val_loss: 0.0232 - val_accuracy: 0.0500\n",
            "Epoch 392/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0221 - accuracy: 0.0000e+00 - val_loss: 0.0232 - val_accuracy: 0.0500\n",
            "Epoch 393/600\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0221 - accuracy: 0.0000e+00 - val_loss: 0.0232 - val_accuracy: 0.0500\n",
            "Epoch 394/600\n",
            "80/80 [==============================] - 0s 169us/step - loss: 0.0221 - accuracy: 0.0000e+00 - val_loss: 0.0232 - val_accuracy: 0.0500\n",
            "Epoch 395/600\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0231 - val_accuracy: 0.0500\n",
            "Epoch 396/600\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0230 - val_accuracy: 0.0500\n",
            "Epoch 397/600\n",
            "80/80 [==============================] - 0s 183us/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0230 - val_accuracy: 0.0500\n",
            "Epoch 398/600\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0230 - val_accuracy: 0.0500\n",
            "Epoch 399/600\n",
            "80/80 [==============================] - 0s 274us/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0230 - val_accuracy: 0.0500\n",
            "Epoch 400/600\n",
            "80/80 [==============================] - 0s 264us/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0231 - val_accuracy: 0.0500\n",
            "Epoch 401/600\n",
            "80/80 [==============================] - 0s 183us/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0231 - val_accuracy: 0.0500\n",
            "Epoch 402/600\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0230 - val_accuracy: 0.0500\n",
            "Epoch 403/600\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0500\n",
            "Epoch 404/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0500\n",
            "Epoch 405/600\n",
            "80/80 [==============================] - 0s 178us/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0500\n",
            "Epoch 406/600\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0220 - accuracy: 0.0000e+00 - val_loss: 0.0230 - val_accuracy: 0.0500\n",
            "Epoch 407/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0219 - accuracy: 0.0000e+00 - val_loss: 0.0230 - val_accuracy: 0.0500\n",
            "Epoch 408/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0219 - accuracy: 0.0000e+00 - val_loss: 0.0230 - val_accuracy: 0.0500\n",
            "Epoch 409/600\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0219 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0500\n",
            "Epoch 410/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0500\n",
            "Epoch 411/600\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0219 - accuracy: 0.0000e+00 - val_loss: 0.0228 - val_accuracy: 0.0500\n",
            "Epoch 412/600\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0219 - accuracy: 0.0000e+00 - val_loss: 0.0228 - val_accuracy: 0.0500\n",
            "Epoch 413/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0228 - val_accuracy: 0.0500\n",
            "Epoch 414/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0500\n",
            "Epoch 415/600\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0230 - val_accuracy: 0.0500\n",
            "Epoch 416/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0219 - accuracy: 0.0000e+00 - val_loss: 0.0231 - val_accuracy: 0.0500\n",
            "Epoch 417/600\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0230 - val_accuracy: 0.0500\n",
            "Epoch 418/600\n",
            "80/80 [==============================] - 0s 178us/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0500\n",
            "Epoch 419/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: 0.0228 - val_accuracy: 0.0500\n",
            "Epoch 420/600\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 421/600\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 422/600\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: 0.0228 - val_accuracy: 0.0500\n",
            "Epoch 423/600\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: 0.0228 - val_accuracy: 0.0500\n",
            "Epoch 424/600\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: 0.0230 - val_accuracy: 0.0500\n",
            "Epoch 425/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: 0.0231 - val_accuracy: 0.0500\n",
            "Epoch 426/600\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: 0.0231 - val_accuracy: 0.0500\n",
            "Epoch 427/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0500\n",
            "Epoch 428/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0216 - accuracy: 0.0000e+00 - val_loss: 0.0228 - val_accuracy: 0.0500\n",
            "Epoch 429/600\n",
            "80/80 [==============================] - 0s 240us/step - loss: 0.0217 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 430/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0216 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 431/600\n",
            "80/80 [==============================] - 0s 178us/step - loss: 0.0216 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 432/600\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0216 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 433/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0216 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 434/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0215 - accuracy: 0.0000e+00 - val_loss: 0.0228 - val_accuracy: 0.0500\n",
            "Epoch 435/600\n",
            "80/80 [==============================] - 0s 220us/step - loss: 0.0216 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0500\n",
            "Epoch 436/600\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0216 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0500\n",
            "Epoch 437/600\n",
            "80/80 [==============================] - 0s 179us/step - loss: 0.0215 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0500\n",
            "Epoch 438/600\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0215 - accuracy: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.0500\n",
            "Epoch 439/600\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0215 - accuracy: 0.0000e+00 - val_loss: 0.0228 - val_accuracy: 0.0500\n",
            "Epoch 440/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0215 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 441/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0215 - accuracy: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.0500\n",
            "Epoch 442/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0215 - accuracy: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.0500\n",
            "Epoch 443/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0215 - accuracy: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.0500\n",
            "Epoch 444/600\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0214 - accuracy: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.0500\n",
            "Epoch 445/600\n",
            "80/80 [==============================] - 0s 181us/step - loss: 0.0214 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 446/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0214 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 447/600\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0214 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 448/600\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0214 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 449/600\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0214 - accuracy: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.0500\n",
            "Epoch 450/600\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0214 - accuracy: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.0500\n",
            "Epoch 451/600\n",
            "80/80 [==============================] - 0s 172us/step - loss: 0.0213 - accuracy: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.0500\n",
            "Epoch 452/600\n",
            "80/80 [==============================] - 0s 166us/step - loss: 0.0213 - accuracy: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.0500\n",
            "Epoch 453/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0213 - accuracy: 0.0000e+00 - val_loss: 0.0225 - val_accuracy: 0.0500\n",
            "Epoch 454/600\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0213 - accuracy: 0.0000e+00 - val_loss: 0.0225 - val_accuracy: 0.0500\n",
            "Epoch 455/600\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0213 - accuracy: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.0500\n",
            "Epoch 456/600\n",
            "80/80 [==============================] - 0s 174us/step - loss: 0.0213 - accuracy: 0.0000e+00 - val_loss: 0.0227 - val_accuracy: 0.0500\n",
            "Epoch 457/600\n",
            "80/80 [==============================] - 0s 167us/step - loss: 0.0213 - accuracy: 0.0000e+00 - val_loss: 0.0225 - val_accuracy: 0.0500\n",
            "Epoch 458/600\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0225 - val_accuracy: 0.0500\n",
            "Epoch 459/600\n",
            "80/80 [==============================] - 0s 190us/step - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0225 - val_accuracy: 0.0500\n",
            "Epoch 460/600\n",
            "80/80 [==============================] - 0s 174us/step - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0225 - val_accuracy: 0.0500\n",
            "Epoch 461/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0500\n",
            "Epoch 462/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0500\n",
            "Epoch 463/600\n",
            "80/80 [==============================] - 0s 167us/step - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0500\n",
            "Epoch 464/600\n",
            "80/80 [==============================] - 0s 203us/step - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0225 - val_accuracy: 0.0500\n",
            "Epoch 465/600\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0226 - val_accuracy: 0.0500\n",
            "Epoch 466/600\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0225 - val_accuracy: 0.0500\n",
            "Epoch 467/600\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0211 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0500\n",
            "Epoch 468/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0211 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0500\n",
            "Epoch 469/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0211 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0500\n",
            "Epoch 470/600\n",
            "80/80 [==============================] - 0s 284us/step - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 471/600\n",
            "80/80 [==============================] - 0s 252us/step - loss: 0.0211 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 472/600\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0211 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0500\n",
            "Epoch 473/600\n",
            "80/80 [==============================] - 0s 188us/step - loss: 0.0211 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0500\n",
            "Epoch 474/600\n",
            "80/80 [==============================] - 0s 179us/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0225 - val_accuracy: 0.0500\n",
            "Epoch 475/600\n",
            "80/80 [==============================] - 0s 178us/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0225 - val_accuracy: 0.0500\n",
            "Epoch 476/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0211 - accuracy: 0.0000e+00 - val_loss: 0.0225 - val_accuracy: 0.0500\n",
            "Epoch 477/600\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0500\n",
            "Epoch 478/600\n",
            "80/80 [==============================] - 0s 209us/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 479/600\n",
            "80/80 [==============================] - 0s 179us/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 480/600\n",
            "80/80 [==============================] - 0s 179us/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 481/600\n",
            "80/80 [==============================] - 0s 172us/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 482/600\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 483/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 484/600\n",
            "80/80 [==============================] - 0s 182us/step - loss: 0.0209 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 485/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0209 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 486/600\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.0221 - val_accuracy: 0.0500\n",
            "Epoch 487/600\n",
            "80/80 [==============================] - 0s 174us/step - loss: 0.0209 - accuracy: 0.0000e+00 - val_loss: 0.0221 - val_accuracy: 0.0500\n",
            "Epoch 488/600\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0209 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 489/600\n",
            "80/80 [==============================] - 0s 177us/step - loss: 0.0209 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 490/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0209 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 491/600\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0208 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 492/600\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0208 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 493/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0209 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 494/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0208 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 495/600\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0208 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 496/600\n",
            "80/80 [==============================] - 0s 179us/step - loss: 0.0208 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 497/600\n",
            "80/80 [==============================] - 0s 266us/step - loss: 0.0208 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 498/600\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0208 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 499/600\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 500/600\n",
            "80/80 [==============================] - 0s 202us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 501/600\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 502/600\n",
            "80/80 [==============================] - 0s 218us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0224 - val_accuracy: 0.0500\n",
            "Epoch 503/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 504/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 505/600\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 506/600\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 507/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 508/600\n",
            "80/80 [==============================] - 0s 242us/step - loss: 0.0206 - accuracy: 0.0000e+00 - val_loss: 0.0221 - val_accuracy: 0.0500\n",
            "Epoch 509/600\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0221 - val_accuracy: 0.0500\n",
            "Epoch 510/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0206 - accuracy: 0.0000e+00 - val_loss: 0.0221 - val_accuracy: 0.0500\n",
            "Epoch 511/600\n",
            "80/80 [==============================] - 0s 212us/step - loss: 0.0206 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 512/600\n",
            "80/80 [==============================] - 0s 227us/step - loss: 0.0206 - accuracy: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.0500\n",
            "Epoch 513/600\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0223 - val_accuracy: 0.0500\n",
            "Epoch 514/600\n",
            "80/80 [==============================] - 0s 318us/step - loss: 0.0206 - accuracy: 0.0000e+00 - val_loss: 0.0221 - val_accuracy: 0.0500\n",
            "Epoch 515/600\n",
            "80/80 [==============================] - 0s 213us/step - loss: 0.0206 - accuracy: 0.0000e+00 - val_loss: 0.0220 - val_accuracy: 0.0500\n",
            "Epoch 516/600\n",
            "80/80 [==============================] - 0s 226us/step - loss: 0.0206 - accuracy: 0.0000e+00 - val_loss: 0.0220 - val_accuracy: 0.0500\n",
            "Epoch 517/600\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0205 - accuracy: 0.0000e+00 - val_loss: 0.0220 - val_accuracy: 0.0500\n",
            "Epoch 518/600\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0205 - accuracy: 0.0000e+00 - val_loss: 0.0220 - val_accuracy: 0.0500\n",
            "Epoch 519/600\n",
            "80/80 [==============================] - 0s 225us/step - loss: 0.0205 - accuracy: 0.0000e+00 - val_loss: 0.0220 - val_accuracy: 0.0500\n",
            "Epoch 520/600\n",
            "80/80 [==============================] - 0s 231us/step - loss: 0.0205 - accuracy: 0.0000e+00 - val_loss: 0.0220 - val_accuracy: 0.0500\n",
            "Epoch 521/600\n",
            "80/80 [==============================] - 0s 232us/step - loss: 0.0205 - accuracy: 0.0000e+00 - val_loss: 0.0219 - val_accuracy: 0.0500\n",
            "Epoch 522/600\n",
            "80/80 [==============================] - 0s 229us/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0219 - val_accuracy: 0.0500\n",
            "Epoch 523/600\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0219 - val_accuracy: 0.0500\n",
            "Epoch 524/600\n",
            "80/80 [==============================] - 0s 217us/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0218 - val_accuracy: 0.0500\n",
            "Epoch 525/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0218 - val_accuracy: 0.0500\n",
            "Epoch 526/600\n",
            "80/80 [==============================] - 0s 184us/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0219 - val_accuracy: 0.0500\n",
            "Epoch 527/600\n",
            "80/80 [==============================] - 0s 185us/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0218 - val_accuracy: 0.0500\n",
            "Epoch 528/600\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0218 - val_accuracy: 0.0500\n",
            "Epoch 529/600\n",
            "80/80 [==============================] - 0s 214us/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0218 - val_accuracy: 0.0500\n",
            "Epoch 530/600\n",
            "80/80 [==============================] - 0s 282us/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 531/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 532/600\n",
            "80/80 [==============================] - 0s 238us/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 533/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0204 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 534/600\n",
            "80/80 [==============================] - 0s 206us/step - loss: 0.0203 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 535/600\n",
            "80/80 [==============================] - 0s 186us/step - loss: 0.0203 - accuracy: 0.0000e+00 - val_loss: 0.0218 - val_accuracy: 0.0500\n",
            "Epoch 536/600\n",
            "80/80 [==============================] - 0s 182us/step - loss: 0.0203 - accuracy: 0.0000e+00 - val_loss: 0.0218 - val_accuracy: 0.0500\n",
            "Epoch 537/600\n",
            "80/80 [==============================] - 0s 219us/step - loss: 0.0203 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 538/600\n",
            "80/80 [==============================] - 0s 172us/step - loss: 0.0203 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 539/600\n",
            "80/80 [==============================] - 0s 207us/step - loss: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 540/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0203 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 541/600\n",
            "80/80 [==============================] - 0s 196us/step - loss: 0.0203 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 542/600\n",
            "80/80 [==============================] - 0s 174us/step - loss: 0.0203 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 543/600\n",
            "80/80 [==============================] - 0s 172us/step - loss: 0.0203 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 544/600\n",
            "80/80 [==============================] - 0s 204us/step - loss: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 545/600\n",
            "80/80 [==============================] - 0s 215us/step - loss: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 546/600\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 547/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 548/600\n",
            "80/80 [==============================] - 0s 173us/step - loss: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 549/600\n",
            "80/80 [==============================] - 0s 199us/step - loss: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 550/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 551/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0201 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 552/600\n",
            "80/80 [==============================] - 0s 210us/step - loss: 0.0202 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 553/600\n",
            "80/80 [==============================] - 0s 251us/step - loss: 0.0201 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 554/600\n",
            "80/80 [==============================] - 0s 163us/step - loss: 0.0201 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 555/600\n",
            "80/80 [==============================] - 0s 195us/step - loss: 0.0201 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 556/600\n",
            "80/80 [==============================] - 0s 197us/step - loss: 0.0201 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 557/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0201 - accuracy: 0.0000e+00 - val_loss: 0.0214 - val_accuracy: 0.0500\n",
            "Epoch 558/600\n",
            "80/80 [==============================] - 0s 193us/step - loss: 0.0201 - accuracy: 0.0000e+00 - val_loss: 0.0214 - val_accuracy: 0.0500\n",
            "Epoch 559/600\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 560/600\n",
            "80/80 [==============================] - 0s 174us/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 561/600\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 562/600\n",
            "80/80 [==============================] - 0s 172us/step - loss: 0.0201 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 563/600\n",
            "80/80 [==============================] - 0s 167us/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 564/600\n",
            "80/80 [==============================] - 0s 187us/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 565/600\n",
            "80/80 [==============================] - 0s 168us/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 566/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 567/600\n",
            "80/80 [==============================] - 0s 176us/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 568/600\n",
            "80/80 [==============================] - 0s 170us/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 569/600\n",
            "80/80 [==============================] - 0s 164us/step - loss: 0.0199 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 570/600\n",
            "80/80 [==============================] - 0s 180us/step - loss: 0.0199 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 571/600\n",
            "80/80 [==============================] - 0s 189us/step - loss: 0.0199 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 572/600\n",
            "80/80 [==============================] - 0s 230us/step - loss: 0.0199 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 573/600\n",
            "80/80 [==============================] - 0s 164us/step - loss: 0.0199 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 574/600\n",
            "80/80 [==============================] - 0s 176us/step - loss: 0.0199 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 575/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0198 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 576/600\n",
            "80/80 [==============================] - 0s 171us/step - loss: 0.0199 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 577/600\n",
            "80/80 [==============================] - 0s 255us/step - loss: 0.0198 - accuracy: 0.0000e+00 - val_loss: 0.0217 - val_accuracy: 0.0500\n",
            "Epoch 578/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0198 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 579/600\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0198 - accuracy: 0.0000e+00 - val_loss: 0.0216 - val_accuracy: 0.0500\n",
            "Epoch 580/600\n",
            "80/80 [==============================] - 0s 205us/step - loss: 0.0198 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 581/600\n",
            "80/80 [==============================] - 0s 177us/step - loss: 0.0198 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 582/600\n",
            "80/80 [==============================] - 0s 176us/step - loss: 0.0197 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 583/600\n",
            "80/80 [==============================] - 0s 185us/step - loss: 0.0198 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 584/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0198 - accuracy: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.0500\n",
            "Epoch 585/600\n",
            "80/80 [==============================] - 0s 192us/step - loss: 0.0198 - accuracy: 0.0000e+00 - val_loss: 0.0214 - val_accuracy: 0.0500\n",
            "Epoch 586/600\n",
            "80/80 [==============================] - 0s 167us/step - loss: 0.0197 - accuracy: 0.0000e+00 - val_loss: 0.0214 - val_accuracy: 0.0500\n",
            "Epoch 587/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0197 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0500\n",
            "Epoch 588/600\n",
            "80/80 [==============================] - 0s 191us/step - loss: 0.0198 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0500\n",
            "Epoch 589/600\n",
            "80/80 [==============================] - 0s 183us/step - loss: 0.0197 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0500\n",
            "Epoch 590/600\n",
            "80/80 [==============================] - 0s 194us/step - loss: 0.0197 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0500\n",
            "Epoch 591/600\n",
            "80/80 [==============================] - 0s 200us/step - loss: 0.0197 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0500\n",
            "Epoch 592/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0197 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0500\n",
            "Epoch 593/600\n",
            "80/80 [==============================] - 0s 178us/step - loss: 0.0197 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0500\n",
            "Epoch 594/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0197 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0500\n",
            "Epoch 595/600\n",
            "80/80 [==============================] - 0s 201us/step - loss: 0.0196 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0500\n",
            "Epoch 596/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0196 - accuracy: 0.0000e+00 - val_loss: 0.0212 - val_accuracy: 0.0500\n",
            "Epoch 597/600\n",
            "80/80 [==============================] - 0s 221us/step - loss: 0.0196 - accuracy: 0.0000e+00 - val_loss: 0.0212 - val_accuracy: 0.0500\n",
            "Epoch 598/600\n",
            "80/80 [==============================] - 0s 223us/step - loss: 0.0196 - accuracy: 0.0000e+00 - val_loss: 0.0212 - val_accuracy: 0.0500\n",
            "Epoch 599/600\n",
            "80/80 [==============================] - 0s 198us/step - loss: 0.0196 - accuracy: 0.0000e+00 - val_loss: 0.0212 - val_accuracy: 0.0500\n",
            "Epoch 600/600\n",
            "80/80 [==============================] - 0s 208us/step - loss: 0.0196 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBynSYkpnt9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym0WsntUoVTs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b3c79ec9-a9e4-463a-ee69-05c1d7b4f7cd"
      },
      "source": [
        "plt.scatter(range(20), results, c='r')\n",
        "plt.scatter(range(20), y_test, c='g')\n",
        "plt.show()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-EJdacao5k2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "f2db2478-d6a2-4edc-fe80-25196d4ad303"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GO5UBxApUid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}